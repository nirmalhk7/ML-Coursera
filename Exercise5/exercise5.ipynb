{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Exercise 5:\n",
    "# Regularized Linear Regression and Bias vs Variance\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this exercise, you will implement regularized linear regression and use it to study models with different bias-variance properties. Before starting on the programming exercise, we strongly recommend watching the video lectures and completing the review questions for the associated topics.\n",
    "\n",
    "All the information you need for solving this assignment is in this notebook, and all the code you will be implementing will take place within this notebook. The assignment can be promptly submitted to the coursera grader directly from this notebook (code and instructions are included below).\n",
    "\n",
    "Before we begin with the exercises, we need to import all libraries required for this programming exercise. Throughout the course, we will be using [`numpy`](http://www.numpy.org/) for all arrays and matrix operations, [`matplotlib`](https://matplotlib.org/) for plotting, and [`scipy`](https://docs.scipy.org/doc/scipy/reference/) for scientific and numerical computation functions and tools. You can find instructions on how to install required libraries in the README file in the [github repository](https://github.com/dibgerge/ml-coursera-python-assignments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "\n",
    "import math\n",
    "\n",
    "# will be used to load MATLAB mat datafile format\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# library written for this exercise providing additional functions for assignment submission, and others\n",
    "import utils\n",
    "\n",
    "# define the submission/grader object for this exercise\n",
    "grader = utils.Grader()\n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission and Grading\n",
    "\n",
    "\n",
    "After completing each part of the assignment, be sure to submit your solutions to the grader. The following is a breakdown of how each part of this exercise is scored.\n",
    "\n",
    "\n",
    "| Section | Part                                             | Submitted Function                | Points |\n",
    "| :-      |:-                                                |:-                                 | :-:    |\n",
    "| 1       | [Regularized Linear Regression Cost Function](#section1)      | [`linearRegCostFunction`](#linearRegCostFunction) |  25    |\n",
    "| 2       | [Regularized Linear Regression Gradient](#section2)           | [`linearRegCostFunction`](#linearRegCostFunction) |25      |\n",
    "| 3       | [Learning Curve](#section3)                                   | [`learningCurve`](#func2)         | 20     |\n",
    "| 4       | [Polynomial Feature Mapping](#section4)                       | [`polyFeatures`](#polyFeatures)          | 10     |\n",
    "| 5       | [Cross Validation Curve](#section5)                           | [`validationCurve`](#validationCurve)       | 20     |\n",
    "|         | Total Points                                     |                                   |100     |\n",
    "\n",
    "\n",
    "You are allowed to submit your solutions multiple times, and we will take only the highest score into consideration.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "At the end of each section in this notebook, we have a cell which contains code for submitting the solutions thus far to the grader. Execute the cell to see your score up to the current section. For all your work to be submitted properly, you must execute those cells at least once.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "## 1 Regularized Linear Regression\n",
    "\n",
    "In the first half of the exercise, you will implement regularized linear regression to predict the amount of water flowing out of a dam using the change of water level in a reservoir. In the next half, you will go through some diagnostics of debugging learning algorithms and examine the effects of bias v.s.\n",
    "variance. \n",
    "\n",
    "### 1.1 Visualizing the dataset\n",
    "\n",
    "We will begin by visualizing the dataset containing historical records on the change in the water level, $x$, and the amount of water flowing out of the dam, $y$. This dataset is divided into three parts:\n",
    "\n",
    "- A **training** set that your model will learn on: `X`, `y`\n",
    "- A **cross validation** set for determining the regularization parameter: `Xval`, `yval`\n",
    "- A **test** set for evaluating performance. These are “unseen” examples which your model did not see during training: `Xtest`, `ytest`\n",
    "\n",
    "Run the next cell to plot the training data. In the following parts, you will implement linear regression and use that to fit a straight line to the data and plot learning curves. Following that, you will implement polynomial regression to find a better fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load from ex5data1.mat, where all variables will be store in a dictionary\n",
    "data = loadmat(os.path.join('Data', 'ex5data1.mat'))\n",
    "\n",
    "# Extract train, test, validation data from dictionary\n",
    "# and also convert y's form 2-D matrix (MATLAB format) to a numpy vector\n",
    "X, y = data['X'], data['y'][:, 0]\n",
    "Xtest, ytest = data['Xtest'], data['ytest'][:, 0]\n",
    "Xval, yval = data['Xval'], data['yval'][:, 0]\n",
    "\n",
    "# m = Number of examples\n",
    "m = y.size\n",
    "\n",
    "# Plot training data\n",
    "pyplot.plot(X, y, 'ro', ms=10, mec='k', mew=1)\n",
    "pyplot.xlabel('Change in water level (x)')\n",
    "pyplot.ylabel('Water flowing out of the dam (y)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Regularized linear regression cost function\n",
    "\n",
    "Recall that regularized linear regression has the following cost function:\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2m} \\left( \\sum_{i=1}^m \\left( h_\\theta\\left( x^{(i)} \\right) - y^{(i)} \\right)^2 \\right) + \\frac{\\lambda}{2m} \\left( \\sum_{j=1}^n \\theta_j^2 \\right)$$\n",
    "\n",
    "where $\\lambda$ is a regularization parameter which controls the degree of regularization (thus, help preventing overfitting). The regularization term puts a penalty on the overall cost J. As the magnitudes of the model parameters $\\theta_j$ increase, the penalty increases as well. Note that you should not regularize\n",
    "the $\\theta_0$ term.\n",
    "\n",
    "You should now complete the code in the function `linearRegCostFunction` in the next cell. Your task is to calculate the regularized linear regression cost function. If possible, try to vectorize your code and avoid writing loops.\n",
    "<a id=\"linearRegCostFunction\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearRegCostFunction(X, y, theta, lambda_=0.0):\n",
    "    \"\"\"\n",
    "    Compute cost and gradient for regularized linear regression \n",
    "    with multiple variables. Computes the cost of using theta as\n",
    "    the parameter for linear regression to fit the data points in X and y. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The dataset. Matrix with shape (m x n + 1) where m is the \n",
    "        total number of examples, and n is the number of features \n",
    "        before adding the bias term.\n",
    "    \n",
    "    y : array_like\n",
    "        The functions values at each datapoint. A vector of\n",
    "        shape (m, ).\n",
    "    \n",
    "    theta : array_like\n",
    "        The parameters for linear regression. A vector of shape (n+1,).\n",
    "    \n",
    "    lambda_ : float, optional\n",
    "        The regularization parameter.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    J : float\n",
    "        The computed cost function. \n",
    "    \n",
    "    grad : array_like\n",
    "        The value of the cost function gradient w.r.t theta. \n",
    "        A vector of shape (n+1, ).\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Compute the cost and gradient of regularized linear regression for\n",
    "    a particular choice of theta.\n",
    "    You should set J to the cost and grad to the gradient.\n",
    "    \"\"\"\n",
    "    # Initialize some useful values\n",
    "    m = y.size # number of training examples\n",
    "\n",
    "    # You need to return the following variables correctly \n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    h=np.dot(X,theta.T)\n",
    "    J=(1/(2*m))*np.sum(np.square((h-y)))\n",
    "    theta[0]=0\n",
    "    J=J+(lambda_/(2*m))*np.sum(np.square(theta))\n",
    "    \n",
    "    grad=(1/m)*((h-y).dot(X))\n",
    "    \n",
    "    grad[1:]=grad[1:]+(lambda_/m)*theta[1:]\n",
    "    # ============================================================\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are finished, the next cell will run your cost function using `theta` initialized at `[1, 1]`. You should expect to see an output of 303.993."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at theta = [1, 1]:\t   303.993192 \n",
      "This value should be about 303.993192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "theta = np.array([1, 1])\n",
    "J, _ = linearRegCostFunction(np.concatenate([np.ones((m, 1)), X], axis=1), y, theta, 1)\n",
    "\n",
    "print('Cost at theta = [1, 1]:\\t   %f ' % J)\n",
    "print('This value should be about 303.993192\\n' % J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing a part of the exercise, you can submit your solutions for grading by first adding the function you modified to the submission object, and then sending your function to Coursera for grading. \n",
    "\n",
    "The submission script will prompt you for your login e-mail and submission token. You can obtain a submission token from the web page for the assignment. You are allowed to submit your solutions multiple times, and we will take only the highest score into consideration.\n",
    "\n",
    "*Execute the following cell to grade your solution to the first part of this exercise.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitting Solutions | Programming Exercise regularized-linear-regression-and-bias-variance\n",
      "\n",
      "Use token from last successful submission (nirmalhk7@gmail.com)? (Y/n): \n",
      "[0.07071042 0.10090476 0.11922749] [0.  0.2 0.3]\n",
      "                                  Part Name |     Score | Feedback\n",
      "                                  --------- |     ----- | --------\n",
      "Regularized Linear Regression Cost Function |  25 /  25 | Nice work!\n",
      "     Regularized Linear Regression Gradient |  25 /  25 | Nice work!\n",
      "                             Learning Curve |   0 /  20 | \n",
      "                 Polynomial Feature Mapping |   0 /  10 | \n",
      "                           Validation Curve |   0 /  20 | \n",
      "                                  --------------------------------\n",
      "                                            |  50 / 100 |  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "grader[1] = linearRegCostFunction\n",
    "grader.grade()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "### 1.3 Regularized linear regression gradient\n",
    "\n",
    "Correspondingly, the partial derivative of the cost function for regularized linear regression is defined as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "& \\frac{\\partial J(\\theta)}{\\partial \\theta_0} = \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta \\left(x^{(i)} \\right) - y^{(i)} \\right) x_j^{(i)} & \\qquad \\text{for } j = 0 \\\\\n",
    "& \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\left( \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta \\left( x^{(i)} \\right) - y^{(i)} \\right) x_j^{(i)} \\right) + \\frac{\\lambda}{m} \\theta_j & \\qquad \\text{for } j \\ge 1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In the function [`linearRegCostFunction`](#linearRegCostFunction) above, add code to calculate the gradient, returning it in the variable `grad`. <font color='red'><b>Do not forget to re-execute the cell containing this function to update the function's definition.</b></font>\n",
    "\n",
    "\n",
    "When you are finished, use the next cell to  run your gradient function using theta initialized at `[1, 1]`. You should expect to see a gradient of `[-15.30, 598.250]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient at theta = [1, 1]:  [-15.303016, 598.250744] \n",
      " (this value should be about [-15.303016, 598.250744])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "theta = np.array([1, 1])\n",
    "J, grad = linearRegCostFunction(np.concatenate([np.ones((m, 1)), X], axis=1), y, theta, 1)\n",
    "\n",
    "print('Gradient at theta = [1, 1]:  [{:.6f}, {:.6f}] '.format(*grad))\n",
    "print(' (this value should be about [-15.303016, 598.250744])\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You should now submit your solutions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitting Solutions | Programming Exercise regularized-linear-regression-and-bias-variance\n",
      "\n",
      "Use token from last successful submission (nirmalhk7@gmail.com)? (Y/n): \n",
      "                                  Part Name |     Score | Feedback\n",
      "                                  --------- |     ----- | --------\n",
      "Regularized Linear Regression Cost Function |  25 /  25 | Nice work!\n",
      "     Regularized Linear Regression Gradient |  25 /  25 | Nice work!\n",
      "                             Learning Curve |   0 /  20 | \n",
      "                 Polynomial Feature Mapping |   0 /  10 | \n",
      "                           Validation Curve |   0 /  20 | \n",
      "                                  --------------------------------\n",
      "                                            |  50 / 100 |  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "grader[2] = linearRegCostFunction\n",
    "grader.grade()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting linear regression\n",
    "\n",
    "Once your cost function and gradient are working correctly, the next cell will run the code in `trainLinearReg` (found in the module `utils.py`) to compute the optimal values of $\\theta$. This training function uses `scipy`'s optimization module to minimize the cost function.\n",
    "\n",
    "In this part, we set regularization parameter $\\lambda$ to zero. Because our current implementation of linear regression is trying to fit a 2-dimensional $\\theta$, regularization will not be incredibly helpful for a $\\theta$ of such low dimension. In the later parts of the exercise, you will be using polynomial regression with regularization.\n",
    "\n",
    "Finally, the code in the next cell should also plot the best fit line, which should look like the figure below. \n",
    "\n",
    "![](Figures/linear_fit.png)\n",
    "\n",
    "The best fit line tells us that the model is not a good fit to the data because the data has a non-linear pattern. While visualizing the best fit as shown is one possible way to debug your learning algorithm, it is not always easy to visualize the data and model. In the next section, you will implement a function to generate learning curves that can help you debug your learning algorithm even if it is not easy to visualize the\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add a columns of ones for the y-intercept\n",
    "X_aug = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "theta = utils.trainLinearReg(linearRegCostFunction, X_aug, y, lambda_=0)\n",
    "\n",
    "#  Plot fit over the data\n",
    "pyplot.plot(X, y, 'ro', ms=10, mec='k', mew=1.5)\n",
    "pyplot.xlabel('Change in water level (x)')\n",
    "pyplot.ylabel('Water flowing out of the dam (y)')\n",
    "pyplot.plot(X, np.dot(X_aug, theta), '--', lw=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "## 2 Bias-variance\n",
    "\n",
    "An important concept in machine learning is the bias-variance tradeoff. Models with high bias are not complex enough for the data and tend to underfit, while models with high variance overfit to the training data.\n",
    "\n",
    "In this part of the exercise, you will plot training and test errors on a learning curve to diagnose bias-variance problems.\n",
    "\n",
    "### 2.1 Learning Curves\n",
    "\n",
    "You will now implement code to generate the learning curves that will be useful in debugging learning algorithms. Recall that a learning curve plots training and cross validation error as a function of training set size. Your job is to fill in the function `learningCurve` in the next cell, so that it returns a vector of errors for the training set and cross validation set.\n",
    "\n",
    "To plot the learning curve, we need a training and cross validation set error for different training set sizes. To obtain different training set sizes, you should use different subsets of the original training set `X`. Specifically, for a training set size of $i$, you should use the first $i$ examples (i.e., `X[:i, :]`\n",
    "and `y[:i]`).\n",
    "\n",
    "You can use the `trainLinearReg` function (by calling `utils.trainLinearReg(...)`) to find the $\\theta$ parameters. Note that the `lambda_` is passed as a parameter to the `learningCurve` function.\n",
    "After learning the $\\theta$ parameters, you should compute the error on the training and cross validation sets. Recall that the training error for a dataset is defined as\n",
    "\n",
    "$$ J_{\\text{train}} = \\frac{1}{2m} \\left[ \\sum_{i=1}^m \\left(h_\\theta \\left( x^{(i)} \\right) - y^{(i)} \\right)^2 \\right] $$\n",
    "\n",
    "In particular, note that the training error does not include the regularization term. One way to compute the training error is to use your existing cost function and set $\\lambda$ to 0 only when using it to compute the training error and cross validation error. When you are computing the training set error, make sure you compute it on the training subset (i.e., `X[:n,:]` and `y[:n]`) instead of the entire training set. However, for the cross validation error, you should compute it over the entire cross validation set. You should store\n",
    "the computed errors in the vectors error train and error val.\n",
    "\n",
    "<a id=\"func2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningCurve(X, y, Xval, yval, lambda_=0):\n",
    "    \"\"\"\n",
    "    Generates the train and cross validation set errors needed to plot a learning curve\n",
    "    returns the train and cross validation set errors for a learning curve. \n",
    "    \n",
    "    In this function, you will compute the train and test errors for\n",
    "    dataset sizes from 1 up to m. In practice, when working with larger\n",
    "    datasets, you might want to do this in larger intervals.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The training dataset. Matrix with shape (m x n + 1) where m is the \n",
    "        total number of examples, and n is the number of features \n",
    "        before adding the bias term.\n",
    "    \n",
    "    y : array_like\n",
    "        The functions values at each training datapoint. A vector of\n",
    "        shape (m, ).\n",
    "    \n",
    "    Xval : array_like\n",
    "        The validation dataset. Matrix with shape (m_val x n + 1) where m is the \n",
    "        total number of examples, and n is the number of features \n",
    "        before adding the bias term.\n",
    "    \n",
    "    yval : array_like\n",
    "        The functions values at each validation datapoint. A vector of\n",
    "        shape (m_val, ).\n",
    "    \n",
    "    lambda_ : float, optional\n",
    "        The regularization parameter.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    error_train : array_like\n",
    "        A vector of shape m. error_train[i] contains the training error for\n",
    "        i examples.\n",
    "    error_val : array_like\n",
    "        A vecotr of shape m. error_val[i] contains the validation error for\n",
    "        i training examples.\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Fill in this function to return training errors in error_train and the\n",
    "    cross validation errors in error_val. i.e., error_train[i] and \n",
    "    error_val[i] should give you the errors obtained after training on i examples.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - You should evaluate the training error on the first i training\n",
    "      examples (i.e., X[:i, :] and y[:i]).\n",
    "    \n",
    "      For the cross-validation error, you should instead evaluate on\n",
    "      the _entire_ cross validation set (Xval and yval).\n",
    "    \n",
    "    - If you are using your cost function (linearRegCostFunction) to compute\n",
    "      the training and cross validation error, you should call the function with\n",
    "      the lambda argument set to 0. Do note that you will still need to use\n",
    "      lambda when running the training to obtain the theta parameters.\n",
    "    \n",
    "    Hint\n",
    "    ----\n",
    "    You can loop over the examples with the following:\n",
    "     \n",
    "           for i in range(1, m+1):\n",
    "               # Compute train/cross validation errors using training examples \n",
    "               # X[:i, :] and y[:i], storing the result in \n",
    "               # error_train[i-1] and error_val[i-1]\n",
    "               ....  \n",
    "    \"\"\"\n",
    "    # Number of training examples\n",
    "    m = y.size\n",
    "\n",
    "    # You need to return these values correctly\n",
    "    error_train = np.zeros(m)\n",
    "    error_val   = np.zeros(m)\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    for i in range(1, m + 1):\n",
    "        theta_t = utils.trainLinearReg(linearRegCostFunction, X[:i], y[:i], lambda_ = lambda_)\n",
    "        error_train[i - 1], _ = linearRegCostFunction(X[:i], y[:i], theta_t, lambda_ = 0)\n",
    "        error_val[i - 1], _ = linearRegCostFunction(Xval, yval, theta_t, lambda_ = 0)\n",
    "    # =============================================================\n",
    "    return error_train, error_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are finished implementing the function `learningCurve`, executing the next cell prints the learning curves and produce a plot similar to the figure below. \n",
    "\n",
    "![](Figures/learning_curve.png)\n",
    "\n",
    "In the learning curve figure, you can observe that both the train error and cross validation error are high when the number of training examples is increased. This reflects a high bias problem in the model - the linear regression model is too simple and is unable to fit our dataset well. In the next section, you will implement polynomial regression to fit a better model for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Training Examples\tTrain Error\tCross Validation Error\n",
      "  \t1\t\t0.000035\t205.224398\n",
      "  \t2\t\t1.144453\t166.874885\n",
      "  \t3\t\t102.713795\t154.510533\n",
      "  \t4\t\t104.766754\t184.625836\n",
      "  \t5\t\t163.389625\t130.023050\n",
      "  \t6\t\t135.977759\t132.187067\n",
      "  \t7\t\t124.299927\t130.579899\n",
      "  \t8\t\t121.410121\t129.770345\n",
      "  \t9\t\t108.594971\t129.706162\n",
      "  \t10\t\t113.196084\t130.005154\n",
      "  \t11\t\t104.008239\t129.875377\n",
      "  \t12\t\t105.412142\t129.498600\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "X_aug = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "Xval_aug = np.concatenate([np.ones((yval.size, 1)), Xval], axis=1)\n",
    "error_train, error_val = learningCurve(X_aug, y, Xval_aug, yval, lambda_=0)\n",
    "\n",
    "pyplot.plot(np.arange(1, m+1), error_train, np.arange(1, m+1), error_val, lw=2)\n",
    "pyplot.title('Learning curve for linear regression')\n",
    "pyplot.legend(['Train', 'Cross Validation'])\n",
    "pyplot.xlabel('Number of training examples')\n",
    "pyplot.ylabel('Error')\n",
    "pyplot.axis([0, 13, 0, 150])\n",
    "\n",
    "print('# Training Examples\\tTrain Error\\tCross Validation Error')\n",
    "for i in range(m):\n",
    "    print('  \\t%d\\t\\t%f\\t%f' % (i+1, error_train[i], error_val[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You should now submit your solutions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitting Solutions | Programming Exercise regularized-linear-regression-and-bias-variance\n",
      "\n",
      "Use token from last successful submission (nirmalhk7@gmail.com)? (Y/n): y\n",
      "[0.07071042 0.10090476 0.11922749] [0.  0.2 0.3]\n",
      "[0.07071042 0.10090476 0.11922749] [0.  0.2 0.3]\n",
      "[-0.84147098 -0.70807342 -0.45464871] [0. 0. 0.]\n",
      "[-0.84147096 -0.70807339 -0.45464869] [0.00000000e+00 1.05511161e-08 6.77479377e-09]\n",
      "[-0.84147097 -0.7080734  -0.4546487 ] [0.00000000e+00 1.05511161e-08 6.77479377e-09]\n",
      "[0.         0.35403671 0.22732436] [0.         0.35403671 0.22732436]\n",
      "[-4.20735492e-01  5.55111512e-17  5.55111512e-17] [0.         0.35403671 0.22732436]\n",
      "[1.08445206e-08 3.54036718e-01 2.27324362e-01] [0.         0.35403671 0.22732436]\n",
      "[-4.20735493e-01 -1.13428872e-09 -1.36018224e-09] [0.         0.35403671 0.22732436]\n",
      "[0.39033214 0.66724641 0.40569101] [0.         0.33879324 0.19479365]\n",
      "[-0.45113885 -0.04082701 -0.04895771] [0.         0.33879324 0.19479365]\n",
      "[0.19516607 0.51064156 0.31650768] [0.         0.34641497 0.211059  ]\n",
      "[-0.43593717 -0.02041351 -0.02447885] [0.         0.34641497 0.211059  ]\n",
      "[0.09758303 0.43233913 0.27191602] [0.         0.35022584 0.21919168]\n",
      "[-0.42833633 -0.01020675 -0.01223943] [0.         0.35022584 0.21919168]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.07318728 0.41276353 0.2607681 ] [0.         0.35117856 0.22122485]\n",
      "[-0.42643612 -0.00765506 -0.00917957] [0.         0.35117856 0.22122485]\n",
      "[0.0609894  0.40297572 0.25519415] [0.         0.35165492 0.22224143]\n",
      "[-0.42548602 -0.00637922 -0.00764964] [0.         0.35165492 0.22224143]\n",
      "[0.05489046 0.39808182 0.25240717] [0.         0.3518931  0.22274973]\n",
      "[-0.42501096 -0.0057413  -0.00688468] [0.         0.3518931  0.22274973]\n",
      "[0.05184099 0.39563487 0.25101368] [0.         0.35201219 0.22300387]\n",
      "[-0.42477344 -0.00542234 -0.0065022 ] [0.         0.35201219 0.22300387]\n",
      "[0.05031625 0.3944114  0.25031693] [0.         0.35207173 0.22313095]\n",
      "[-0.42465467 -0.00526286 -0.00631095] [0.         0.35207173 0.22313095]\n",
      "[0.04955388 0.39379966 0.24996856] [0.         0.3521015  0.22319448]\n",
      "[-0.42459529 -0.00518312 -0.00621533] [0.         0.3521015  0.22319448]\n",
      "[0.0491727  0.39349379 0.24979437] [0.         0.35211639 0.22322625]\n",
      "[-0.4245656  -0.00514325 -0.00616752] [0.         0.35211639 0.22322625]\n",
      "[0.04898211 0.39334086 0.24970728] [0.         0.35212383 0.22324213]\n",
      "[-0.42455076 -0.00512331 -0.00614362] [0.         0.35212383 0.22324213]\n",
      "[0.04888681 0.39326439 0.24966373] [0.         0.35212755 0.22325008]\n",
      "[-0.42454333 -0.00511334 -0.00613167] [0.         0.35212755 0.22325008]\n",
      "[0.04883917 0.39322616 0.24964196] [0.         0.35212941 0.22325405]\n",
      "[-0.42453962 -0.00510836 -0.00612569] [0.         0.35212941 0.22325405]\n",
      "[0.04881534 0.39320704 0.24963107] [0.         0.35213034 0.22325603]\n",
      "[-0.42453777 -0.00510587 -0.0061227 ] [0.         0.35213034 0.22325603]\n",
      "[0.04880343 0.39319748 0.24962563] [0.         0.35213081 0.22325703]\n",
      "[-0.42453684 -0.00510462 -0.00612121] [0.         0.35213081 0.22325703]\n",
      "[0.04879747 0.3931927  0.24962291] [0.         0.35213104 0.22325752]\n",
      "[-0.42453638 -0.005104   -0.00612046] [0.         0.35213104 0.22325752]\n",
      "[0.0487945  0.39319031 0.24962155] [0.         0.35213116 0.22325777]\n",
      "[-0.42453614 -0.00510369 -0.00612009] [0.         0.35213116 0.22325777]\n",
      "[0.04879301 0.39318912 0.24962087] [0.         0.35213122 0.22325789]\n",
      "[-0.42453603 -0.00510353 -0.0061199 ] [0.         0.35213122 0.22325789]\n",
      "[0.04879226 0.39318852 0.24962053] [0.         0.35213125 0.22325796]\n",
      "[-0.42453597 -0.00510345 -0.00611981] [0.         0.35213125 0.22325796]\n",
      "[0.04879189 0.39318822 0.24962036] [0.         0.35213126 0.22325799]\n",
      "[-0.42453594 -0.00510342 -0.00611976] [0.         0.35213126 0.22325799]\n",
      "[0.0487917  0.39318807 0.24962027] [0.         0.35213127 0.223258  ]\n",
      "[-0.42453593 -0.0051034  -0.00611974] [0.         0.35213127 0.223258  ]\n",
      "[0.04879161 0.393188   0.24962023] [0.         0.35213127 0.22325801]\n",
      "[-0.42453592 -0.00510339 -0.00611972] [0.         0.35213127 0.22325801]\n",
      "[0.04879156 0.39318796 0.24962021] [0.         0.35213127 0.22325801]\n",
      "[-0.42453592 -0.00510338 -0.00611972] [0.         0.35213127 0.22325801]\n",
      "[0.04879154 0.39318794 0.2496202 ] [0.         0.35213127 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611972] [0.         0.35213127 0.22325802]\n",
      "[0.04879153 0.39318793 0.24962019] [0.         0.35213127 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213127 0.22325802]\n",
      "[0.04879152 0.39318793 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.47116582 0.75359173 0.48381146] [0.         0.35711936 0.22923948]\n",
      "[-0.41710678  0.0061361   0.00387572] [0.         0.35711936 0.22923948]\n",
      "[0.25997867 0.57338983 0.36671582] [0.         0.35462532 0.22624875]\n",
      "[-0.42082135  0.00051636 -0.00112199] [0.         0.35462532 0.22624875]\n",
      "[0.15438509 0.48328887 0.30816801] [0.         0.3533783  0.22475338]\n",
      "[-0.42267863 -0.00229351 -0.00362085] [0.         0.3533783  0.22475338]\n",
      "[0.10158831 0.4382384  0.2788941 ] [0.         0.35275479 0.2240057 ]\n",
      "[-0.42360727 -0.00369844 -0.00487028] [0.         0.35275479 0.2240057 ]\n",
      "[0.07518991 0.41571316 0.26425714] [0.         0.35244303 0.22363186]\n",
      "[-0.42407159 -0.00440091 -0.005495  ] [0.         0.35244303 0.22363186]\n",
      "[0.06199071 0.40445054 0.25693867] [0.         0.35228715 0.22344494]\n",
      "[-0.42430375 -0.00475214 -0.00580736] [0.         0.35228715 0.22344494]\n",
      "[0.05539112 0.39881923 0.25327943] [0.         0.35220921 0.22335148]\n",
      "[-0.42441983 -0.00492776 -0.00596353] [0.         0.35220921 0.22335148]\n",
      "[0.05209132 0.39600358 0.25144981] [0.         0.35217024 0.22330475]\n",
      "[-0.42447787 -0.00501557 -0.00604162] [0.         0.35217024 0.22330475]\n",
      "[0.05044142 0.39459575 0.250535  ] [0.         0.35215076 0.22328138]\n",
      "[-0.42450689 -0.00505947 -0.00608067] [0.         0.35215076 0.22328138]\n",
      "[0.04961647 0.39389184 0.25007759] [0.         0.35214102 0.2232697 ]\n",
      "[-0.4245214  -0.00508142 -0.00610019] [0.         0.35214102 0.2232697 ]\n",
      "[0.04920399 0.39353988 0.24984889] [0.         0.35213615 0.22326386]\n",
      "[-0.42452866 -0.0050924  -0.00610995] [0.         0.35213615 0.22326386]\n",
      "[0.04899775 0.3933639  0.24973454] [0.         0.35213371 0.22326094]\n",
      "[-0.42453228 -0.00509789 -0.00611483] [0.         0.35213371 0.22326094]\n",
      "[0.04889464 0.39327591 0.24967736] [0.         0.35213249 0.22325948]\n",
      "[-0.4245341  -0.00510063 -0.00611727] [0.         0.35213249 0.22325948]\n",
      "[0.04884308 0.39323192 0.24964878] [0.         0.35213188 0.22325875]\n",
      "[-0.424535   -0.005102   -0.00611849] [0.         0.35213188 0.22325875]\n",
      "[0.0488173  0.39320992 0.24963448] [0.         0.35213158 0.22325838]\n",
      "[-0.42453546 -0.00510269 -0.0061191 ] [0.         0.35213158 0.22325838]\n",
      "[0.04880441 0.39319892 0.24962733] [0.         0.35213143 0.2232582 ]\n",
      "[-0.42453568 -0.00510303 -0.00611941] [0.         0.35213143 0.2232582 ]\n",
      "[0.04879796 0.39319342 0.24962376] [0.         0.35213135 0.22325811]\n",
      "[-0.4245358  -0.0051032  -0.00611956] [0.         0.35213135 0.22325811]\n",
      "[0.04879474 0.39319067 0.24962197] [0.         0.35213131 0.22325806]\n",
      "[-0.42453585 -0.00510329 -0.00611964] [0.         0.35213131 0.22325806]\n",
      "[0.04879313 0.3931893  0.24962108] [0.         0.35213129 0.22325804]\n",
      "[-0.42453588 -0.00510333 -0.00611968] [0.         0.35213129 0.22325804]\n",
      "[0.04879232 0.39318861 0.24962063] [0.         0.35213128 0.22325803]\n",
      "[-0.4245359  -0.00510335 -0.00611969] [0.         0.35213128 0.22325803]\n",
      "[0.04879192 0.39318827 0.24962041] [0.         0.35213128 0.22325802]\n",
      "[-0.4245359  -0.00510337 -0.0061197 ] [0.         0.35213128 0.22325802]\n",
      "[0.04879172 0.39318809 0.2496203 ] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510337 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879162 0.39318801 0.24962024] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510337 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879157 0.39318796 0.24962022] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510337 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879154 0.39318794 0.2496202 ] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879153 0.39318793 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318793 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[0.04879152 0.39318792 0.24962019] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.00510338 -0.00611971] [0.         0.35213128 0.22325802]\n",
      "[-0.42453591 -0.35723465 -0.22937773] [0.         0.35213128 0.22325802]\n",
      "[-0.09187589  0.13362719  0.23887725] [0.         0.35213128 0.22325802]\n",
      "[-0.04233424 -0.1275741  -0.5304781 ] [0. 0. 0.]\n",
      "[-0.04233424 -0.1275741  -0.53047809] [0.00000000e+00 1.90100227e-09 7.90473968e-09]\n",
      "[-0.04233424 -0.1275741  -0.53047809] [0.00000000e+00 1.90100227e-09 7.90473968e-09]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521166  0.03422496 -0.00485229] [0.         0.13257356 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257356 0.55126685]\n",
      "[ 0.92432303  0.60855045 -0.17739128] [ 0.         -0.0018706   0.50460767]\n",
      "[-0.10949229 -0.13576718 -0.04256041] [ 0.         -0.0018706   0.50460767]\n",
      "[ 0.47476733  0.3213877  -0.09112178] [0.         0.06535148 0.52793726]\n",
      "[-0.06413696 -0.06660807 -0.02083753] [0.         0.06535148 0.52793726]\n",
      "[ 0.24998949  0.17780632 -0.04798703] [0.         0.09896252 0.53960205]\n",
      "[-0.04145929 -0.03202851 -0.00997609] [0.         0.09896252 0.53960205]\n",
      "[ 0.13760056  0.10601564 -0.02641966] [0.         0.11576805 0.54543445]\n",
      "[-0.03012046 -0.01473873 -0.00454537] [0.         0.11576805 0.54543445]\n",
      "[ 0.0814061   0.07012029 -0.01563597] [0.         0.12417081 0.54835065]\n",
      "[-0.02445105 -0.00609384 -0.00183001] [0.         0.12417081 0.54835065]\n",
      "[ 0.05330887  0.05217262 -0.01024413] [0.         0.12837219 0.54980875]\n",
      "[-0.02161634 -0.0017714  -0.00047233] [0.         0.12837219 0.54980875]\n",
      "[ 0.03926025  0.04319878 -0.00754821] [0.         0.13047288 0.5505378 ]\n",
      "[-0.02019898  0.00038982  0.00020651] [0.         0.13047288 0.5505378 ]\n",
      "[ 0.03223595  0.03871187 -0.00620025] [0.         0.13152322 0.55090232]\n",
      "[-0.01949031  0.00147043  0.00054593] [0.         0.13152322 0.55090232]\n",
      "[ 0.02872379  0.03646841 -0.00552627] [0.         0.13204839 0.55108459]\n",
      "[-0.01913597  0.00201074  0.00071564] [0.         0.13204839 0.55108459]\n",
      "[ 0.02696772  0.03534668 -0.00518927] [0.         0.13231098 0.55117572]\n",
      "[-0.0189588   0.00228089  0.00080049] [0.         0.13231098 0.55117572]\n",
      "[ 0.02608968  0.03478581 -0.00502078] [0.         0.13244227 0.55122128]\n",
      "[-0.01887021  0.00241597  0.00084292] [0.         0.13244227 0.55122128]\n",
      "[ 0.02565066  0.03450538 -0.00493653] [0.         0.13250792 0.55124406]\n",
      "[-0.01882592  0.00248351  0.00086413] [0.         0.13250792 0.55124406]\n",
      "[ 0.02543115  0.03436516 -0.00489441] [0.         0.13254074 0.55125546]\n",
      "[-0.01880378  0.00251728  0.00087474] [0.         0.13254074 0.55125546]\n",
      "[ 0.02532139  0.03429506 -0.00487335] [0.         0.13255715 0.55126115]\n",
      "[-0.0187927   0.00253416  0.00088004] [0.         0.13255715 0.55126115]\n",
      "[ 0.02526652  0.03426    -0.00486282] [0.         0.13256536 0.551264  ]\n",
      "[-0.01878717  0.0025426   0.00088269] [0.         0.13256536 0.551264  ]\n",
      "[ 0.02523908  0.03424247 -0.00485755] [0.         0.13256946 0.55126542]\n",
      "[-0.0187844   0.00254682  0.00088402] [0.         0.13256946 0.55126542]\n",
      "[ 0.02522536  0.03423371 -0.00485492] [0.         0.13257151 0.55126614]\n",
      "[-0.01878301  0.00254893  0.00088468] [0.         0.13257151 0.55126614]\n",
      "[ 0.0252185   0.03422933 -0.0048536 ] [0.         0.13257254 0.55126649]\n",
      "[-0.01878232  0.00254999  0.00088501] [0.         0.13257254 0.55126649]\n",
      "[ 0.02521507  0.03422714 -0.00485294] [0.         0.13257305 0.55126667]\n",
      "[-0.01878198  0.00255052  0.00088518] [0.         0.13257305 0.55126667]\n",
      "[ 0.02521335  0.03422604 -0.00485261] [0.         0.13257331 0.55126676]\n",
      "[-0.0187818   0.00255078  0.00088526] [0.         0.13257331 0.55126676]\n",
      "[ 0.0252125   0.0342255  -0.00485245] [0.         0.13257344 0.5512668 ]\n",
      "[-0.01878172  0.00255091  0.0008853 ] [0.         0.13257344 0.5512668 ]\n",
      "[ 0.02521207  0.03422522 -0.00485237] [0.         0.1325735  0.55126683]\n",
      "[-0.01878167  0.00255098  0.00088533] [0.         0.1325735  0.55126683]\n",
      "[ 0.02521185  0.03422508 -0.00485233] [0.         0.13257353 0.55126684]\n",
      "[-0.01878165  0.00255101  0.00088534] [0.         0.13257353 0.55126684]\n",
      "[ 0.02521175  0.03422502 -0.00485231] [0.         0.13257355 0.55126684]\n",
      "[-0.01878164  0.00255103  0.00088534] [0.         0.13257355 0.55126684]\n",
      "[ 0.02521169  0.03422498 -0.00485229] [0.         0.13257356 0.55126684]\n",
      "[-0.01878164  0.00255104  0.00088534] [0.         0.13257356 0.55126684]\n",
      "[ 0.02521167  0.03422496 -0.00485229] [0.         0.13257356 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257356 0.55126685]\n",
      "[ 0.02521165  0.03422496 -0.00485229] [0.         0.13257356 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257356 0.55126685]\n",
      "[ 0.02521165  0.03422495 -0.00485229] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485229] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[ 0.02521164  0.03422495 -0.00485228] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163  0.00255104  0.00088535] [0.         0.13257357 0.55126685]\n",
      "[-0.01878163 -0.06373574 -0.27474808] [0.         0.13257357 0.55126685]\n",
      "[-0.06516542  0.0366999   0.40348998] [0.         0.13257357 0.55126685]\n",
      "[-0.24721836  0.08068696 -0.21050703] [0. 0. 0.]\n",
      "[-0.24721836  0.08068696 -0.21050703] [ 0.00000000e+00 -1.20232945e-09  3.13679924e-09]\n",
      "[-0.24721836  0.08068696 -0.21050703] [ 0.00000000e+00 -1.20232945e-09  3.13679924e-09]\n",
      "[0.59251572 0.17394069 0.18557126] [ 0.         -0.41144703  1.07343852]\n",
      "[-0.66812488 -0.11312425  0.5698502 ] [ 0.         -0.41144703  1.07343852]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[0.3825822  0.15062726 0.08655169] [ 0.         -0.30858528  0.80507889]\n",
      "[-0.56289825 -0.06467144  0.37476089] [ 0.         -0.30858528  0.80507889]\n",
      "[0.27761544 0.13897054 0.0370419 ] [ 0.         -0.2571544   0.67089907]\n",
      "[-0.51028493 -0.04044504  0.27721624] [ 0.         -0.2571544   0.67089907]\n",
      "[0.22513206 0.13314219 0.01228701] [ 0.         -0.23143896  0.60380917]\n",
      "[-0.48397828 -0.02833184  0.22844391] [ 0.         -0.23143896  0.60380917]\n",
      "[ 1.98890371e-01  1.30228007e-01 -9.04397461e-05] [ 0.         -0.21858124  0.57026421]\n",
      "[-0.47082495 -0.02227524  0.20405775] [ 0.         -0.21858124  0.57026421]\n",
      "[ 0.18576953  0.12877092 -0.00627916] [ 0.         -0.21215238  0.55349174]\n",
      "[-0.46424828 -0.01924694  0.19186467] [ 0.         -0.21215238  0.55349174]\n",
      "[ 0.1792091   0.12804237 -0.00937352] [ 0.         -0.20893795  0.5451055 ]\n",
      "[-0.46095995 -0.01773279  0.18576813] [ 0.         -0.20893795  0.5451055 ]\n",
      "[ 0.17592889  0.1276781  -0.01092071] [ 0.         -0.20733073  0.54091238]\n",
      "[-0.45931579 -0.01697572  0.18271986] [ 0.         -0.20733073  0.54091238]\n",
      "[ 0.17428879  0.12749596 -0.0116943 ] [ 0.         -0.20652712  0.53881582]\n",
      "[-0.4584937  -0.01659718  0.18119572] [ 0.         -0.20652712  0.53881582]\n",
      "[ 0.17346873  0.1274049  -0.01208109] [ 0.         -0.20612532  0.53776754]\n",
      "[-0.45808266 -0.01640791  0.18043365] [ 0.         -0.20612532  0.53776754]\n",
      "[ 0.17305871  0.12735936 -0.01227449] [ 0.         -0.20592442  0.5372434 ]\n",
      "[-0.45787714 -0.01631328  0.18005262] [ 0.         -0.20592442  0.5372434 ]\n",
      "[ 0.17285369  0.12733659 -0.01237119] [ 0.         -0.20582397  0.53698133]\n",
      "[-0.45777438 -0.01626596  0.1798621 ] [ 0.         -0.20582397  0.53698133]\n",
      "[ 0.17275119  0.12732521 -0.01241954] [ 0.         -0.20577374  0.53685029]\n",
      "[-0.457723   -0.0162423   0.17976684] [ 0.         -0.20577374  0.53685029]\n",
      "[ 0.17269993  0.12731952 -0.01244371] [ 0.         -0.20574863  0.53678478]\n",
      "[-0.45769731 -0.01623047  0.17971921] [ 0.         -0.20574863  0.53678478]\n",
      "[ 0.17267431  0.12731667 -0.0124558 ] [ 0.         -0.20573607  0.53675202]\n",
      "[-0.45768446 -0.01622456  0.1796954 ] [ 0.         -0.20573607  0.53675202]\n",
      "[ 0.17266149  0.12731525 -0.01246184] [ 0.         -0.2057298   0.53673564]\n",
      "[-0.45767804 -0.0162216   0.17968349] [ 0.         -0.2057298   0.53673564]\n",
      "[ 0.17265509  0.12731454 -0.01246486] [ 0.         -0.20572666  0.53672745]\n",
      "[-0.45767483 -0.01622012  0.17967754] [ 0.         -0.20572666  0.53672745]\n",
      "[ 0.17265188  0.12731418 -0.01246638] [ 0.         -0.20572509  0.53672335]\n",
      "[-0.45767322 -0.01621938  0.17967456] [ 0.         -0.20572509  0.53672335]\n",
      "[ 0.17265028  0.12731401 -0.01246713] [ 0.         -0.2057243   0.53672131]\n",
      "[-0.45767242 -0.01621901  0.17967307] [ 0.         -0.2057243   0.53672131]\n",
      "[ 0.17264948  0.12731392 -0.01246751] [ 0.         -0.20572391  0.53672028]\n",
      "[-0.45767202 -0.01621883  0.17967233] [ 0.         -0.20572391  0.53672028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.17264908  0.12731387 -0.0124677 ] [ 0.         -0.20572371  0.53671977]\n",
      "[-0.45767182 -0.01621873  0.17967196] [ 0.         -0.20572371  0.53671977]\n",
      "[ 0.17264888  0.12731385 -0.01246779] [ 0.         -0.20572362  0.53671952]\n",
      "[-0.45767172 -0.01621869  0.17967177] [ 0.         -0.20572362  0.53671952]\n",
      "[ 0.17264878  0.12731384 -0.01246784] [ 0.         -0.20572357  0.53671939]\n",
      "[-0.45767167 -0.01621866  0.17967168] [ 0.         -0.20572357  0.53671939]\n",
      "[ 0.17264873  0.12731383 -0.01246786] [ 0.         -0.20572354  0.53671932]\n",
      "[-0.45767164 -0.01621865  0.17967163] [ 0.         -0.20572354  0.53671932]\n",
      "[ 0.17264871  0.12731383 -0.01246787] [ 0.         -0.20572353  0.53671929]\n",
      "[-0.45767163 -0.01621865  0.17967161] [ 0.         -0.20572353  0.53671929]\n",
      "[ 0.17264869  0.12731383 -0.01246788] [ 0.         -0.20572352  0.53671928]\n",
      "[-0.45767163 -0.01621864  0.1796716 ] [ 0.         -0.20572352  0.53671928]\n",
      "[ 0.17264869  0.12731383 -0.01246788] [ 0.         -0.20572352  0.53671927]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671927]\n",
      "[ 0.17264868  0.12731383 -0.01246788] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264878  0.12731384 -0.01246787] [ 0.         -0.20572355  0.53671934]\n",
      "[-0.45767165 -0.01621865  0.17967164] [ 0.         -0.20572355  0.53671934]\n",
      "[0.97210619 0.2595843  0.11559687] [ 0.         -0.43224862  1.1461063 ]\n",
      "[-0.69501288 -0.12004129  0.62378195] [ 0.         -0.43224862  1.1461063 ]\n",
      "[0.57237743 0.19344906 0.05156449] [ 0.         -0.31898607  0.84141278]\n",
      "[-0.57634225 -0.06812997  0.40172677] [ 0.         -0.31898607  0.84141278]\n",
      "[0.37251306 0.16038145 0.0195483 ] [ 0.         -0.26235479  0.68906602]\n",
      "[-0.51700693 -0.0421743   0.29069918] [ 0.         -0.26235479  0.68906602]\n",
      "[0.27258087 0.14384764 0.00354021] [ 0.         -0.23403916  0.61289264]\n",
      "[-0.48733928 -0.02919647  0.23518538] [ 0.         -0.23403916  0.61289264]\n",
      "[ 0.22261477  0.13558073 -0.00446384] [ 0.         -0.21988134  0.57480595]\n",
      "[-0.47250545 -0.02270756  0.20742848] [ 0.         -0.21988134  0.57480595]\n",
      "[ 0.19763173  0.13144728 -0.00846586] [ 0.         -0.21280243  0.5557626 ]\n",
      "[-0.46508853 -0.0194631   0.19355003] [ 0.         -0.21280243  0.5557626 ]\n",
      "[ 0.1851402   0.12938055 -0.01046687] [ 0.         -0.20926297  0.54624093]\n",
      "[-0.46138008 -0.01784087  0.18661081] [ 0.         -0.20926297  0.54624093]\n",
      "[ 0.17889444  0.12834719 -0.01146738] [ 0.         -0.20749324  0.5414801 ]\n",
      "[-0.45952585 -0.01702976  0.1831412 ] [ 0.         -0.20749324  0.5414801 ]\n",
      "[ 0.17577156  0.12783051 -0.01196763] [ 0.         -0.20660838  0.53909968]\n",
      "[-0.45859873 -0.0166242   0.18140639] [ 0.         -0.20660838  0.53909968]\n",
      "[ 0.17421012  0.12757217 -0.01221776] [ 0.         -0.20616595  0.53790947]\n",
      "[-0.45813518 -0.01642142  0.18053899] [ 0.         -0.20616595  0.53790947]\n",
      "[ 0.1734294   0.127443   -0.01234282] [ 0.         -0.20594473  0.53731436]\n",
      "[-0.4579034  -0.01632003  0.18010529] [ 0.         -0.20594473  0.53731436]\n",
      "[ 0.17303904  0.12737841 -0.01240535] [ 0.         -0.20583413  0.53701681]\n",
      "[-0.45778751 -0.01626934  0.17988844] [ 0.         -0.20583413  0.53701681]\n",
      "[ 0.17284386  0.12734612 -0.01243662] [ 0.         -0.20577882  0.53686804]\n",
      "[-0.45772956 -0.01624399  0.17978001] [ 0.         -0.20577882  0.53686804]\n",
      "[ 0.17274627  0.12732997 -0.01245225] [ 0.         -0.20575117  0.53679365]\n",
      "[-0.45770059 -0.01623132  0.1797258 ] [ 0.         -0.20575117  0.53679365]\n",
      "[ 0.17269748  0.1273219  -0.01246007] [ 0.         -0.20573734  0.53675645]\n",
      "[-0.45768611 -0.01622498  0.17969869] [ 0.         -0.20573734  0.53675645]\n",
      "[ 0.17267308  0.12731786 -0.01246398] [ 0.         -0.20573043  0.53673786]\n",
      "[-0.45767886 -0.01622181  0.17968514] [ 0.         -0.20573043  0.53673786]\n",
      "[ 0.17266088  0.12731585 -0.01246593] [ 0.         -0.20572697  0.53672856]\n",
      "[-0.45767524 -0.01622023  0.17967836] [ 0.         -0.20572697  0.53672856]\n",
      "[ 0.17265478  0.12731484 -0.01246691] [ 0.         -0.20572525  0.53672391]\n",
      "[-0.45767343 -0.01621943  0.17967497] [ 0.         -0.20572525  0.53672391]\n",
      "[ 0.17265173  0.12731433 -0.0124674 ] [ 0.         -0.20572438  0.53672158]\n",
      "[-0.45767252 -0.01621904  0.17967328] [ 0.         -0.20572438  0.53672158]\n",
      "[ 0.17265021  0.12731408 -0.01246764] [ 0.         -0.20572395  0.53672042]\n",
      "[-0.45767207 -0.01621884  0.17967243] [ 0.         -0.20572395  0.53672042]\n",
      "[ 0.17264944  0.12731395 -0.01246776] [ 0.         -0.20572373  0.53671984]\n",
      "[-0.45767185 -0.01621874  0.17967201] [ 0.         -0.20572373  0.53671984]\n",
      "[ 0.17264906  0.12731389 -0.01246783] [ 0.         -0.20572363  0.53671955]\n",
      "[-0.45767173 -0.01621869  0.1796718 ] [ 0.         -0.20572363  0.53671955]\n",
      "[ 0.17264887  0.12731386 -0.01246786] [ 0.         -0.20572357  0.5367194 ]\n",
      "[-0.45767168 -0.01621867  0.17967169] [ 0.         -0.20572357  0.5367194 ]\n",
      "[ 0.17264878  0.12731384 -0.01246787] [ 0.         -0.20572354  0.53671933]\n",
      "[-0.45767165 -0.01621865  0.17967164] [ 0.         -0.20572354  0.53671933]\n",
      "[ 0.17264873  0.12731384 -0.01246788] [ 0.         -0.20572353  0.5367193 ]\n",
      "[-0.45767163 -0.01621865  0.17967161] [ 0.         -0.20572353  0.5367193 ]\n",
      "[ 0.1726487   0.12731383 -0.01246788] [ 0.         -0.20572352  0.53671928]\n",
      "[-0.45767163 -0.01621864  0.1796716 ] [ 0.         -0.20572352  0.53671928]\n",
      "[ 0.17264869  0.12731383 -0.01246788] [ 0.         -0.20572352  0.53671927]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671927]\n",
      "[ 0.17264869  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[ 0.17264868  0.12731383 -0.01246789] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162 -0.01621864  0.17967159] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.45767162  0.05235586  0.00076517] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.08790398 -0.12626951  0.38707063] [ 0.         -0.20572352  0.53671926]\n",
      "[-0.04940849 -0.03544199 -0.06149745] [0. 0. 0.]\n",
      "[-0.04940849 -0.03544198 -0.06149745] [0.00000000e+00 5.28126734e-10 9.16383355e-10]\n",
      "[-0.04940849 -0.03544198 -0.06149745] [0.00000000e+00 5.28126734e-10 9.16383355e-10]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[9.18874901e+00 4.39306726e-03 3.71639481e-02] [0.         0.12481224 0.80623928]\n",
      "[-0.0915915   0.05636226  0.51467263] [0.         0.12481224 0.80623928]\n",
      "[4.6189644  0.01343761 0.03195153] [0.         0.10034843 0.46895555]\n",
      "[-0.07409998  0.0397184   0.27342748] [0.         0.10034843 0.46895555]\n",
      "[2.33407209 0.01795987 0.02934533] [0.         0.08811653 0.30031368]\n",
      "[-0.06535422  0.03139648  0.1528049 ] [0.         0.08811653 0.30031368]\n",
      "[1.19162593 0.02022101 0.02804222] [0.         0.08200058 0.21599275]\n",
      "[-0.06098134  0.02723551  0.09249361] [0.         0.08200058 0.21599275]\n",
      "[0.62040286 0.02135158 0.02739067] [0.         0.0789426  0.17383228]\n",
      "[-0.0587949   0.02515503  0.06233797] [0.         0.0789426  0.17383228]\n",
      "[0.33479132 0.02191686 0.0270649 ] [0.         0.07741361 0.15275205]\n",
      "[-0.05770168  0.02411479  0.04726015] [0.         0.07741361 0.15275205]\n",
      "[0.19198555 0.0221995  0.02690201] [0.         0.07664912 0.14221193]\n",
      "[-0.05715507  0.02359467  0.03972124] [0.         0.07664912 0.14221193]\n",
      "[0.12058266 0.02234082 0.02682056] [0.         0.07626687 0.13694188]\n",
      "[-0.05688176  0.02333461  0.03595178] [0.         0.07626687 0.13694188]\n",
      "[0.08488122 0.02241148 0.02677984] [0.         0.07607575 0.13430685]\n",
      "[-0.05674511  0.02320458  0.03406705] [0.         0.07607575 0.13430685]\n",
      "[0.0670305  0.02244681 0.02675948] [0.         0.07598019 0.13298933]\n",
      "[-0.05667678  0.02313957  0.03312469] [0.         0.07598019 0.13298933]\n",
      "[0.05810514 0.02246448 0.0267493 ] [0.         0.07593241 0.13233057]\n",
      "[-0.05664262  0.02310706  0.03265351] [0.         0.07593241 0.13233057]\n",
      "[0.05364246 0.02247331 0.02674421] [0.         0.07590852 0.1320012 ]\n",
      "[-0.05662554  0.0230908   0.03241792] [0.         0.07590852 0.1320012 ]\n",
      "[0.05141112 0.02247773 0.02674167] [0.         0.07589657 0.13183651]\n",
      "[-0.056617    0.02308268  0.03230012] [0.         0.07589657 0.13183651]\n",
      "[0.05029545 0.02247994 0.02674039] [0.         0.0758906  0.13175416]\n",
      "[-0.05661273  0.02307861  0.03224122] [0.         0.0758906  0.13175416]\n",
      "[0.04973761 0.02248104 0.02673976] [0.         0.07588761 0.13171299]\n",
      "[-0.05661059  0.02307658  0.03221178] [0.         0.07588761 0.13171299]\n",
      "[0.0494587  0.02248159 0.02673944] [0.         0.07588612 0.1316924 ]\n",
      "[-0.05660952  0.02307557  0.03219705] [0.         0.07588612 0.1316924 ]\n",
      "[0.04931924 0.02248187 0.02673928] [0.         0.07588537 0.13168211]\n",
      "[-0.05660899  0.02307506  0.03218969] [0.         0.07588537 0.13168211]\n",
      "[0.04924951 0.02248201 0.0267392 ] [0.         0.075885   0.13167696]\n",
      "[-0.05660872  0.0230748   0.03218601] [0.         0.075885   0.13167696]\n",
      "[0.04921464 0.02248208 0.02673916] [0.         0.07588481 0.13167439]\n",
      "[-0.05660859  0.02307468  0.03218417] [0.         0.07588481 0.13167439]\n",
      "[0.04919721 0.02248211 0.02673914] [0.         0.07588472 0.1316731 ]\n",
      "[-0.05660852  0.02307461  0.03218325] [0.         0.07588472 0.1316731 ]\n",
      "[0.04918849 0.02248213 0.02673913] [0.         0.07588467 0.13167246]\n",
      "[-0.05660849  0.02307458  0.03218279] [0.         0.07588467 0.13167246]\n",
      "[0.04918414 0.02248214 0.02673913] [0.         0.07588465 0.13167214]\n",
      "[-0.05660847  0.02307457  0.03218256] [0.         0.07588465 0.13167214]\n",
      "[0.04918196 0.02248214 0.02673912] [0.         0.07588464 0.13167198]\n",
      "[-0.05660846  0.02307456  0.03218244] [0.         0.07588464 0.13167198]\n",
      "[0.04918087 0.02248214 0.02673912] [0.         0.07588463 0.1316719 ]\n",
      "[-0.05660846  0.02307455  0.03218238] [0.         0.07588463 0.1316719 ]\n",
      "[0.04918032 0.02248214 0.02673912] [0.         0.07588463 0.13167186]\n",
      "[-0.05660846  0.02307455  0.03218236] [0.         0.07588463 0.13167186]\n",
      "[0.04918005 0.02248214 0.02673912] [0.         0.07588463 0.13167184]\n",
      "[-0.05660846  0.02307455  0.03218234] [0.         0.07588463 0.13167184]\n",
      "[0.04917991 0.02248214 0.02673912] [0.         0.07588463 0.13167183]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588463 0.13167183]\n",
      "[0.04917985 0.02248214 0.02673912] [0.         0.07588463 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588463 0.13167182]\n",
      "[0.04917981 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.0491798  0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917979 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[0.04917978 0.02248214 0.02673912] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.02307455  0.03218233] [0.         0.07588462 0.13167182]\n",
      "[-0.05660846  0.00410339 -0.00073563] [0.         0.07588462 0.13167182]\n",
      "[-0.12023863 -0.00153872  0.18407039] [0.         0.07588462 0.13167182]\n",
      "[-0.1235602  -0.08356241 -0.11255093] [0. 0. 0.]\n",
      "[-0.1235602  -0.08356241 -0.11255093] [0.00000000e+00 1.24517695e-09 1.67713958e-09]\n",
      "[-0.1235602  -0.08356241 -0.11255093] [0.00000000e+00 1.24517695e-09 1.67713958e-09]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[4.59895503 0.05970888 0.09131605] [ 0.         -0.60915663 -0.39389623]\n",
      "[-0.24405066 -0.55495272 -0.43956173] [ 0.         -0.60915663 -0.39389623]\n",
      "[2.37775429 0.07008843 0.08360985] [ 0.         -0.22469279 -0.08934961]\n",
      "[-0.1618719  -0.25223428 -0.19477742] [ 0.         -0.22469279 -0.08934961]\n",
      "[1.26715393 0.0752782  0.07975674] [ 0.         -0.03246087  0.0629237 ]\n",
      "[-0.12078252 -0.10087506 -0.07238527] [ 0.         -0.03246087  0.0629237 ]\n",
      "[0.71185374 0.07787309 0.07783019] [0.         0.06365509 0.13906035]\n",
      "[-0.10023783 -0.02519545 -0.01118919] [0.         0.06365509 0.13906035]\n",
      "[0.43420365 0.07917053 0.07686692] [0.         0.11171307 0.17712868]\n",
      "[-0.08996548  0.01264436  0.01940885] [0.         0.11171307 0.17712868]\n",
      "[0.29537861 0.07981926 0.07638528] [0.         0.13574206 0.19616285]\n",
      "[-0.08482931  0.03156426  0.03470787] [0.         0.13574206 0.19616285]\n",
      "[0.22596608 0.08014362 0.07614446] [0.         0.14775656 0.20567993]\n",
      "[-0.08226122  0.04102421  0.04235738] [0.         0.14775656 0.20567993]\n",
      "[0.19125982 0.0803058  0.07602405] [0.         0.15376381 0.21043847]\n",
      "[-0.08097718  0.04575419  0.04618213] [0.         0.15376381 0.21043847]\n",
      "[0.17390669 0.08038689 0.07596385] [0.         0.15676743 0.21281774]\n",
      "[-0.08033516  0.04811918  0.04809451] [0.         0.15676743 0.21281774]\n",
      "[0.16523013 0.08042743 0.07593374] [0.         0.15826924 0.21400737]\n",
      "[-0.08001415  0.04930167  0.0490507 ] [0.         0.15826924 0.21400737]\n",
      "[0.16089184 0.0804477  0.07591869] [0.         0.15902015 0.21460219]\n",
      "[-0.07985364  0.04989292  0.04952879] [0.         0.15902015 0.21460219]\n",
      "[0.1587227  0.08045784 0.07591117] [0.        0.1593956 0.2148996]\n",
      "[-0.07977339  0.05018854  0.04976784] [0.        0.1593956 0.2148996]\n",
      "[0.15763813 0.08046291 0.0759074 ] [0.         0.15958333 0.21504831]\n",
      "[-0.07973326  0.05033635  0.04988736] [0.         0.15958333 0.21504831]\n",
      "[0.15709585 0.08046544 0.07590552] [0.         0.15967719 0.21512266]\n",
      "[-0.0797132   0.05041026  0.04994713] [0.         0.15967719 0.21512266]\n",
      "[0.1568247  0.08046671 0.07590458] [0.         0.15972412 0.21515983]\n",
      "[-0.07970317  0.05044721  0.04997701] [0.         0.15972412 0.21515983]\n",
      "[0.15668913 0.08046734 0.07590411] [0.         0.15974759 0.21517842]\n",
      "[-0.07969815  0.05046569  0.04999195] [0.         0.15974759 0.21517842]\n",
      "[0.15662135 0.08046766 0.07590388] [0.         0.15975932 0.21518772]\n",
      "[-0.07969565  0.05047493  0.04999942] [0.         0.15975932 0.21518772]\n",
      "[0.15658745 0.08046782 0.07590376] [0.         0.15976519 0.21519236]\n",
      "[-0.07969439  0.05047955  0.05000315] [0.         0.15976519 0.21519236]\n",
      "[0.15657051 0.0804679  0.0759037 ] [0.         0.15976812 0.21519469]\n",
      "[-0.07969377  0.05048185  0.05000502] [0.         0.15976812 0.21519469]\n",
      "[0.15656203 0.08046794 0.07590367] [0.         0.15976959 0.21519585]\n",
      "[-0.07969345  0.05048301  0.05000595] [0.         0.15976959 0.21519585]\n",
      "[0.1565578  0.08046796 0.07590366] [0.         0.15977032 0.21519643]\n",
      "[-0.0796933   0.05048359  0.05000642] [0.         0.15977032 0.21519643]\n",
      "[0.15655568 0.08046797 0.07590365] [0.         0.15977069 0.21519672]\n",
      "[-0.07969322  0.05048388  0.05000665] [0.         0.15977069 0.21519672]\n",
      "[0.15655462 0.08046797 0.07590364] [0.         0.15977087 0.21519686]\n",
      "[-0.07969318  0.05048402  0.05000677] [0.         0.15977087 0.21519686]\n",
      "[0.15655409 0.08046797 0.07590364] [0.         0.15977096 0.21519694]\n",
      "[-0.07969316  0.05048409  0.05000683] [0.         0.15977096 0.21519694]\n",
      "[0.15655383 0.08046798 0.07590364] [0.         0.15977101 0.21519697]\n",
      "[-0.07969315  0.05048413  0.05000686] [0.         0.15977101 0.21519697]\n",
      "[0.15655369 0.08046798 0.07590364] [0.         0.15977103 0.21519699]\n",
      "[-0.07969314  0.05048415  0.05000687] [0.         0.15977103 0.21519699]\n",
      "[0.15655363 0.08046798 0.07590364] [0.         0.15977104 0.215197  ]\n",
      "[-0.07969314  0.05048416  0.05000688] [0.         0.15977104 0.215197  ]\n",
      "[0.15655359 0.08046798 0.07590364] [0.         0.15977105 0.215197  ]\n",
      "[-0.07969314  0.05048416  0.05000688] [0.         0.15977105 0.215197  ]\n",
      "[0.15655358 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655357 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[0.15655356 0.08046798 0.07590364] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.05048416  0.05000689] [0.         0.15977105 0.21519701]\n",
      "[-0.07969314  0.01852995  0.00696749] [0.         0.15977105 0.21519701]\n",
      "[-0.10477942  0.04096614  0.22965055] [0.         0.15977105 0.21519701]\n",
      "[-0.05498295 -0.03132083 -0.12267931] [0. 0. 0.]\n",
      "[-0.05498295 -0.03132083 -0.12267931] [0.00000000e+00 4.66716699e-10 1.82806423e-09]\n",
      "[-0.05498295 -0.03132083 -0.12267931] [0.00000000e+00 4.66716699e-10 1.82806423e-09]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.0559965  0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344706  0.00781499  0.01747707] [0.         0.05664763 0.22188088]\n",
      "[ 0.64044386  0.10079788 -0.14335256] [ 0.         -0.05278509 -0.02284903]\n",
      "[-0.06738509 -0.06826399 -0.13699097] [ 0.         -0.05278509 -0.02284903]\n",
      "[ 0.34822017  0.06618227 -0.06338462] [0.         0.00193127 0.09951593]\n",
      "[-0.05541607 -0.0302245  -0.05975695] [0.         0.00193127 0.09951593]\n",
      "[ 0.20210833  0.04887446 -0.02340065] [0.         0.02928945 0.16069841]\n",
      "[-0.04943156 -0.01120475 -0.02113994] [0.         0.02928945 0.16069841]\n",
      "[ 0.12905241  0.04022056 -0.00340866] [0.         0.04296854 0.19128964]\n",
      "[-0.04643931 -0.00169488 -0.00183144] [0.         0.04296854 0.19128964]\n",
      "[0.09252445 0.03589361 0.00658733] [0.         0.04980809 0.20658526]\n",
      "[-0.04494318  0.00306006  0.00782282] [0.         0.04980809 0.20658526]\n",
      "[0.07426047 0.03373013 0.01158533] [0.         0.05322786 0.21423307]\n",
      "[-0.04419512  0.00543753  0.01264994] [0.         0.05322786 0.21423307]\n",
      "[0.06512848 0.03264839 0.01408433] [0.         0.05493775 0.21805698]\n",
      "[-0.04382109  0.00662626  0.01506351] [0.         0.05493775 0.21805698]\n",
      "[0.06056248 0.03210752 0.01533382] [0.         0.05579269 0.21996893]\n",
      "[-0.04363407  0.00722063  0.01627029] [0.         0.05579269 0.21996893]\n",
      "[0.05827948 0.03183709 0.01595857] [0.         0.05622016 0.22092491]\n",
      "[-0.04354056  0.00751781  0.01687368] [0.         0.05622016 0.22092491]\n",
      "[0.05713799 0.03170187 0.01627095] [0.        0.0564339 0.2214029]\n",
      "[-0.04349381  0.0076664   0.01717537] [0.        0.0564339 0.2214029]\n",
      "[0.05656724 0.03163426 0.01642714] [0.         0.05654077 0.22164189]\n",
      "[-0.04347043  0.0077407   0.01732622] [0.         0.05654077 0.22164189]\n",
      "[0.05628186 0.03160046 0.01650523] [0.         0.0565942  0.22176139]\n",
      "[-0.04345874  0.00777785  0.01740165] [0.         0.0565942  0.22176139]\n",
      "[0.05613917 0.03158356 0.01654428] [0.         0.05662092 0.22182114]\n",
      "[-0.0434529   0.00779642  0.01743936] [0.         0.05662092 0.22182114]\n",
      "[0.05606783 0.03157511 0.0165638 ] [0.         0.05663428 0.22185101]\n",
      "[-0.04344998  0.00780571  0.01745821] [0.         0.05663428 0.22185101]\n",
      "[0.05603216 0.03157088 0.01657356] [0.         0.05664095 0.22186595]\n",
      "[-0.04344852  0.00781035  0.01746764] [0.         0.05664095 0.22186595]\n",
      "[0.05601432 0.03156877 0.01657844] [0.         0.05664429 0.22187342]\n",
      "[-0.04344779  0.00781267  0.01747236] [0.         0.05664429 0.22187342]\n",
      "[0.0560054  0.03156771 0.01658088] [0.         0.05664596 0.22187715]\n",
      "[-0.04344742  0.00781384  0.01747471] [0.         0.05664596 0.22187715]\n",
      "[0.05600095 0.03156718 0.0165821 ] [0.         0.0566468  0.22187902]\n",
      "[-0.04344724  0.00781442  0.01747589] [0.         0.0566468  0.22187902]\n",
      "[0.05599872 0.03156692 0.01658271] [0.         0.05664722 0.22187995]\n",
      "[-0.04344715  0.00781471  0.01747648] [0.         0.05664722 0.22187995]\n",
      "[0.0559976  0.03156679 0.01658302] [0.         0.05664743 0.22188042]\n",
      "[-0.0434471   0.00781485  0.01747677] [0.         0.05664743 0.22188042]\n",
      "[0.05599704 0.03156672 0.01658317] [0.         0.05664753 0.22188065]\n",
      "[-0.04344708  0.00781492  0.01747692] [0.         0.05664753 0.22188065]\n",
      "[0.05599677 0.03156669 0.01658325] [0.         0.05664758 0.22188077]\n",
      "[-0.04344707  0.00781496  0.017477  ] [0.         0.05664758 0.22188077]\n",
      "[0.05599663 0.03156667 0.01658329] [0.         0.05664761 0.22188083]\n",
      "[-0.04344706  0.00781498  0.01747703] [0.         0.05664761 0.22188083]\n",
      "[0.05599656 0.03156666 0.0165833 ] [0.         0.05664762 0.22188085]\n",
      "[-0.04344706  0.00781499  0.01747705] [0.         0.05664762 0.22188085]\n",
      "[0.05599652 0.03156666 0.01658331] [0.         0.05664763 0.22188087]\n",
      "[-0.04344706  0.00781499  0.01747706] [0.         0.05664763 0.22188087]\n",
      "[0.0559965  0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344706  0.00781499  0.01747706] [0.         0.05664763 0.22188088]\n",
      "[0.0559965  0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344706  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[0.05599649 0.03156666 0.01658332] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705  0.007815    0.01747707] [0.         0.05664763 0.22188088]\n",
      "[-0.04344705 -0.00162628 -0.01950308] [0.         0.05664763 0.22188088]\n",
      "[-0.11034453 -0.00842068  0.23042025] [0.         0.05664763 0.22188088]\n",
      "[-0.06853927 -0.01519837 -0.08718831] [0. 0. 0.]\n",
      "[-0.06853927 -0.01519837 -0.08718831] [0.00000000e+00 2.26473380e-10 1.29920709e-09]\n",
      "[-0.06853927 -0.01519837 -0.08718831] [0.00000000e+00 2.26473380e-10 1.29920709e-09]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.31332144 0.07626686 0.04058457] [0.         0.03346814 0.27755958]\n",
      "[-0.09969709  0.02381039  0.09327371] [0.         0.03346814 0.27755958]\n",
      "[0.20374844 0.06339672 0.04282804] [0.         0.03756919 0.25830435]\n",
      "[-0.09671982  0.02523498  0.08115905] [0.         0.03756919 0.25830435]\n",
      "[0.14896194 0.05696165 0.04394978] [0.         0.03961971 0.24867673]\n",
      "[-0.09523119  0.02594728  0.07510172] [0.         0.03961971 0.24867673]\n",
      "[0.12156869 0.05374412 0.04451065] [0.         0.04064497 0.24386292]\n",
      "[-0.09448687  0.02630343  0.07207305] [0.         0.04064497 0.24386292]\n",
      "[0.10787206 0.05213535 0.04479109] [0.         0.0411576  0.24145602]\n",
      "[-0.09411471  0.0264815   0.07055872] [0.         0.0411576  0.24145602]\n",
      "[0.10102375 0.05133096 0.0449313 ] [0.         0.04141392 0.24025256]\n",
      "[-0.09392863  0.02657054  0.06980156] [0.         0.04141392 0.24025256]\n",
      "[0.0975996  0.05092877 0.04500141] [0.         0.04154207 0.23965084]\n",
      "[-0.09383559  0.02661506  0.06942297] [0.         0.04154207 0.23965084]\n",
      "[0.09588752 0.05072768 0.04503647] [0.         0.04160615 0.23934997]\n",
      "[-0.09378907  0.02663732  0.06923368] [0.         0.04160615 0.23934997]\n",
      "[0.09503148 0.05062713 0.04505399] [0.         0.04163819 0.23919954]\n",
      "[-0.09376581  0.02664845  0.06913903] [0.         0.04163819 0.23919954]\n",
      "[0.09460346 0.05057685 0.04506276] [0.         0.04165421 0.23912433]\n",
      "[-0.09375418  0.02665401  0.06909171] [0.         0.04165421 0.23912433]\n",
      "[0.09438945 0.05055172 0.04506714] [0.         0.04166222 0.23908672]\n",
      "[-0.09374836  0.02665679  0.06906805] [0.         0.04166222 0.23908672]\n",
      "[0.09428244 0.05053915 0.04506933] [0.         0.04166623 0.23906792]\n",
      "[-0.09374546  0.02665818  0.06905622] [0.         0.04166623 0.23906792]\n",
      "[0.09422894 0.05053286 0.04507043] [0.         0.04166823 0.23905851]\n",
      "[-0.093744    0.02665888  0.0690503 ] [0.         0.04166823 0.23905851]\n",
      "[0.09420219 0.05052972 0.04507097] [0.         0.04166923 0.23905381]\n",
      "[-0.09374328  0.02665923  0.06904735] [0.         0.04166923 0.23905381]\n",
      "[0.09418881 0.05052815 0.04507125] [0.         0.04166973 0.23905146]\n",
      "[-0.09374291  0.0266594   0.06904587] [0.         0.04166973 0.23905146]\n",
      "[0.09418213 0.05052737 0.04507138] [0.         0.04166998 0.23905029]\n",
      "[-0.09374273  0.02665949  0.06904513] [0.         0.04166998 0.23905029]\n",
      "[0.09417878 0.05052697 0.04507145] [0.         0.04167011 0.2390497 ]\n",
      "[-0.09374264  0.02665953  0.06904476] [0.         0.04167011 0.2390497 ]\n",
      "[0.09417711 0.05052678 0.04507149] [0.         0.04167017 0.23904941]\n",
      "[-0.0937426   0.02665955  0.06904457] [0.         0.04167017 0.23904941]\n",
      "[0.09417627 0.05052668 0.0450715 ] [0.         0.0416702  0.23904926]\n",
      "[-0.09374257  0.02665956  0.06904448] [0.         0.0416702  0.23904926]\n",
      "[0.09417586 0.05052663 0.04507151] [0.         0.04167022 0.23904919]\n",
      "[-0.09374256  0.02665957  0.06904444] [0.         0.04167022 0.23904919]\n",
      "[0.09417565 0.0505266  0.04507152] [0.         0.04167022 0.23904915]\n",
      "[-0.09374256  0.02665957  0.06904441] [0.         0.04167022 0.23904915]\n",
      "[0.09417554 0.05052659 0.04507152] [0.         0.04167023 0.23904913]\n",
      "[-0.09374255  0.02665957  0.0690444 ] [0.         0.04167023 0.23904913]\n",
      "[0.09417549 0.05052659 0.04507152] [0.         0.04167023 0.23904912]\n",
      "[-0.09374255  0.02665957  0.06904439] [0.         0.04167023 0.23904912]\n",
      "[0.09417547 0.05052658 0.04507152] [0.         0.04167023 0.23904912]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904912]\n",
      "[0.09417545 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417545 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[0.09417544 0.05052658 0.04507152] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02665958  0.06904439] [0.         0.04167023 0.23904911]\n",
      "[-0.09374255  0.02070669  0.03489452] [0.         0.04167023 0.23904911]\n",
      "[-0.10916235 -0.01516913  0.23894488] [0.         0.04167023 0.23904911]\n",
      "[-0.05886545 -0.01426719 -0.07575504] [0. 0. 0.]\n",
      "[-0.05886545 -0.01426719 -0.07575504] [0.00000000e+00 2.12597655e-10 1.12883803e-09]\n",
      "[-0.05886545 -0.01426719 -0.07575504] [0.00000000e+00 2.12597655e-10 1.12883803e-09]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[4.44851865 0.01318576 0.04325808] [0.         0.02796134 0.59402064]\n",
      "[-0.08923857  0.00547115  0.27564319] [0.         0.02796134 0.59402064]\n",
      "[2.27309059 0.01320927 0.04325365] [0.         0.03427886 0.4047884 ]\n",
      "[-0.07953697  0.00920959  0.16373511] [0.         0.03427886 0.4047884 ]\n",
      "[1.18537656 0.01322103 0.04325144] [0.         0.03743762 0.31017228]\n",
      "[-0.07468617  0.01107881  0.10778107] [0.         0.03743762 0.31017228]\n",
      "[0.64151955 0.01322691 0.04325033] [0.         0.039017   0.26286422]\n",
      "[-0.07226077  0.01201342  0.07980405] [0.         0.039017   0.26286422]\n",
      "[0.36959104 0.01322985 0.04324978] [0.         0.03980669 0.23921019]\n",
      "[-0.07104807  0.01248072  0.06581554] [0.         0.03980669 0.23921019]\n",
      "[0.23362678 0.01323132 0.0432495 ] [0.         0.04020153 0.22738317]\n",
      "[-0.07044172  0.01271438  0.05882129] [0.         0.04020153 0.22738317]\n",
      "[0.16564466 0.01323206 0.04324936] [0.         0.04039895 0.22146967]\n",
      "[-0.07013855  0.0128312   0.05532416] [0.         0.04039895 0.22146967]\n",
      "[0.13165359 0.01323242 0.04324929] [0.         0.04049767 0.21851291]\n",
      "[-0.06998696  0.01288962  0.0535756 ] [0.         0.04049767 0.21851291]\n",
      "[0.11465806 0.01323261 0.04324926] [0.         0.04054702 0.21703453]\n",
      "[-0.06991117  0.01291882  0.05270131] [0.         0.04054702 0.21703453]\n",
      "[0.1061603  0.0132327  0.04324924] [0.         0.0405717  0.21629535]\n",
      "[-0.06987327  0.01293343  0.05226417] [0.         0.0405717  0.21629535]\n",
      "[0.10191141 0.01323275 0.04324923] [0.         0.04058404 0.21592575]\n",
      "[-0.06985432  0.01294073  0.0520456 ] [0.         0.04058404 0.21592575]\n",
      "[0.09978697 0.01323277 0.04324923] [0.         0.04059021 0.21574095]\n",
      "[-0.06984485  0.01294438  0.05193632] [0.         0.04059021 0.21574095]\n",
      "[0.09872475 0.01323278 0.04324922] [0.         0.04059329 0.21564856]\n",
      "[-0.06984011  0.0129462   0.05188167] [0.         0.04059329 0.21564856]\n",
      "[0.09819364 0.01323279 0.04324922] [0.         0.04059483 0.21560236]\n",
      "[-0.06983774  0.01294712  0.05185435] [0.         0.04059483 0.21560236]\n",
      "[0.09792809 0.01323279 0.04324922] [0.         0.04059561 0.21557926]\n",
      "[-0.06983656  0.01294757  0.05184069] [0.         0.04059561 0.21557926]\n",
      "[0.09779531 0.01323279 0.04324922] [0.         0.04059599 0.21556771]\n",
      "[-0.06983597  0.0129478   0.05183386] [0.         0.04059599 0.21556771]\n",
      "[0.09772892 0.01323279 0.04324922] [0.         0.04059618 0.21556193]\n",
      "[-0.06983567  0.01294792  0.05183045] [0.         0.04059618 0.21556193]\n",
      "[0.09769572 0.01323279 0.04324922] [0.         0.04059628 0.21555905]\n",
      "[-0.06983552  0.01294797  0.05182874] [0.         0.04059628 0.21555905]\n",
      "[0.09767913 0.01323279 0.04324922] [0.         0.04059633 0.2155576 ]\n",
      "[-0.06983545  0.012948    0.05182789] [0.         0.04059633 0.2155576 ]\n",
      "[0.09767083 0.01323279 0.04324922] [0.         0.04059635 0.21555688]\n",
      "[-0.06983541  0.01294802  0.05182746] [0.         0.04059635 0.21555688]\n",
      "[0.09766668 0.01323279 0.04324922] [0.         0.04059636 0.21555652]\n",
      "[-0.06983539  0.01294802  0.05182725] [0.         0.04059636 0.21555652]\n",
      "[0.0976646  0.01323279 0.04324922] [0.         0.04059637 0.21555634]\n",
      "[-0.06983538  0.01294803  0.05182714] [0.         0.04059637 0.21555634]\n",
      "[0.09766357 0.01323279 0.04324922] [0.         0.04059637 0.21555625]\n",
      "[-0.06983538  0.01294803  0.05182709] [0.         0.04059637 0.21555625]\n",
      "[0.09766305 0.01323279 0.04324922] [0.         0.04059637 0.2155562 ]\n",
      "[-0.06983538  0.01294803  0.05182706] [0.         0.04059637 0.2155562 ]\n",
      "[0.09766279 0.01323279 0.04324922] [0.         0.04059638 0.21555618]\n",
      "[-0.06983538  0.01294803  0.05182705] [0.         0.04059638 0.21555618]\n",
      "[0.09766266 0.01323279 0.04324922] [0.         0.04059638 0.21555617]\n",
      "[-0.06983538  0.01294803  0.05182704] [0.         0.04059638 0.21555617]\n",
      "[0.0976626  0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983538  0.01294803  0.05182704] [0.         0.04059638 0.21555616]\n",
      "[0.09766256 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983538  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766255 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766254 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[0.09766253 0.01323279 0.04324922] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.01294803  0.05182703] [0.         0.04059638 0.21555616]\n",
      "[-0.06983537  0.00787348  0.02488251] [0.         0.04059638 0.21555616]\n",
      "[-0.11211581 -0.01630075  0.22671469] [0.         0.04059638 0.21555616]\n",
      "[-0.03761909 -0.00650307 -0.05399313] [0. 0. 0.]\n",
      "[-0.03761909 -0.00650307 -0.05399313] [0.00000000e+00 9.69033345e-11 8.04560274e-10]\n",
      "[-0.03761909 -0.00650307 -0.05399313] [0.00000000e+00 9.69033345e-11 8.04560274e-10]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.05273682 0.0114755  0.02482853] [0.         0.01435997 0.11922668]\n",
      "[-0.03033303  0.00747183  0.02023425] [0.         0.01435997 0.11922668]\n",
      "[ 0.2094754  -0.01001279 -0.03570194] [ 0.         -0.02622821  0.00931098]\n",
      "[-0.03836825 -0.02195796 -0.04940921] [ 0.         -0.02622821  0.00931098]\n",
      "[ 0.1311061   0.00073136 -0.0054367 ] [ 0.         -0.00593412  0.06426883]\n",
      "[-0.03435064 -0.00724307 -0.01458748] [ 0.         -0.00593412  0.06426883]\n",
      "[0.09192145 0.00610343 0.00969591] [0.         0.00421293 0.09174776]\n",
      "[-0.03234183  0.00011438  0.00282339] [0.         0.00421293 0.09174776]\n",
      "[0.07232913 0.00878947 0.01726222] [0.         0.00928645 0.10548722]\n",
      "[-0.03133743  0.00379311  0.01152883] [0.         0.00928645 0.10548722]\n",
      "[0.06253297 0.01013248 0.02104538] [0.         0.01182321 0.11235695]\n",
      "[-0.03083523  0.00563247  0.01588154] [0.         0.01182321 0.11235695]\n",
      "[0.05763489 0.01080399 0.02293695] [0.         0.01309159 0.11579182]\n",
      "[-0.03058413  0.00655215  0.0180579 ] [0.         0.01309159 0.11579182]\n",
      "[0.05518584 0.01113975 0.02388274] [0.         0.01372578 0.11750925]\n",
      "[-0.03045858  0.00701199  0.01914608] [0.         0.01372578 0.11750925]\n",
      "[0.05396132 0.01130762 0.02435564] [0.         0.01404288 0.11836797]\n",
      "[-0.0303958   0.00724191  0.01969017] [0.         0.01404288 0.11836797]\n",
      "[0.05334906 0.01139156 0.02459208] [0.         0.01420142 0.11879733]\n",
      "[-0.03036442  0.00735687  0.01996222] [0.         0.01420142 0.11879733]\n",
      "[0.05304293 0.01143353 0.02471031] [0.         0.0142807  0.11901201]\n",
      "[-0.03034872  0.00741435  0.02009824] [0.         0.0142807  0.11901201]\n",
      "[0.05288987 0.01145452 0.02476942] [0.         0.01432034 0.11911935]\n",
      "[-0.03034087  0.00744309  0.02016625] [0.         0.01432034 0.11911935]\n",
      "[0.05281334 0.01146501 0.02479898] [0.         0.01434015 0.11917302]\n",
      "[-0.03033695  0.00745746  0.02020025] [0.         0.01434015 0.11917302]\n",
      "[0.05277507 0.01147026 0.02481375] [0.         0.01435006 0.11919985]\n",
      "[-0.03033499  0.00746465  0.02021726] [0.         0.01435006 0.11919985]\n",
      "[0.05275594 0.01147288 0.02482114] [0.         0.01435502 0.11921327]\n",
      "[-0.03033401  0.00746824  0.02022576] [0.         0.01435502 0.11921327]\n",
      "[0.05274637 0.01147419 0.02482484] [0.         0.0143575  0.11921998]\n",
      "[-0.03033352  0.00747004  0.02023001] [0.         0.0143575  0.11921998]\n",
      "[0.05274159 0.01147485 0.02482668] [0.         0.01435873 0.11922333]\n",
      "[-0.03033327  0.00747093  0.02023213] [0.         0.01435873 0.11922333]\n",
      "[0.0527392  0.01147517 0.02482761] [0.         0.01435935 0.11922501]\n",
      "[-0.03033315  0.00747138  0.0202332 ] [0.         0.01435935 0.11922501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.052738   0.01147534 0.02482807] [0.         0.01435966 0.11922585]\n",
      "[-0.03033309  0.00747161  0.02023373] [0.         0.01435966 0.11922585]\n",
      "[0.0527374  0.01147542 0.0248283 ] [0.         0.01435982 0.11922627]\n",
      "[-0.03033306  0.00747172  0.02023399] [0.         0.01435982 0.11922627]\n",
      "[0.0527371  0.01147546 0.02482842] [0.         0.0143599  0.11922648]\n",
      "[-0.03033304  0.00747178  0.02023413] [0.         0.0143599  0.11922648]\n",
      "[0.05273695 0.01147548 0.02482847] [0.         0.01435993 0.11922658]\n",
      "[-0.03033304  0.00747181  0.02023419] [0.         0.01435993 0.11922658]\n",
      "[0.05273688 0.01147549 0.0248285 ] [0.         0.01435995 0.11922663]\n",
      "[-0.03033303  0.00747182  0.02023423] [0.         0.01435995 0.11922663]\n",
      "[0.05273684 0.0114755  0.02482852] [0.         0.01435996 0.11922666]\n",
      "[-0.03033303  0.00747183  0.02023424] [0.         0.01435996 0.11922666]\n",
      "[0.05273682 0.0114755  0.02482852] [0.         0.01435997 0.11922667]\n",
      "[-0.03033303  0.00747183  0.02023425] [0.         0.01435997 0.11922667]\n",
      "[0.05273681 0.0114755  0.02482853] [0.         0.01435997 0.11922668]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922668]\n",
      "[0.05273681 0.0114755  0.02482853] [0.         0.01435997 0.11922668]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922668]\n",
      "[0.05273681 0.0114755  0.02482853] [0.         0.01435997 0.11922668]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922668]\n",
      "[0.05273681 0.0114755  0.02482853] [0.         0.01435997 0.11922668]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922668]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922668]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922668]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[0.0527368  0.0114755  0.02482853] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00747183  0.02023426] [0.         0.01435997 0.11922669]\n",
      "[-0.03033303  0.00587628  0.00698685] [0.         0.01435997 0.11922669]\n",
      "[-0.12557821 -0.03143402  0.17599453] [0.         0.01435997 0.11922669]\n",
      "[-0.06094776 -0.03117961 -0.03897871] [0. 0. 0.]\n",
      "[-0.06094776 -0.03117961 -0.03897871] [0.00000000e+00 4.64612449e-10 5.80828035e-10]\n",
      "[-0.06094776 -0.03117961 -0.03897871] [0.00000000e+00 4.64612449e-10 5.80828035e-10]\n",
      "[0.16736739 0.06708022 0.04164056] [0.         0.10823428 0.1353074 ]\n",
      "[-0.04420153  0.03812357  0.0386187 ] [0.         0.10823428 0.1353074 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.1102886  0.04251526 0.02148574] [0.         0.08117571 0.10148055]\n",
      "[-0.04838809  0.02079777  0.01921935] [0.         0.08117571 0.10148055]\n",
      "[0.08174921 0.03023278 0.01140833] [0.         0.06764643 0.08456713]\n",
      "[-0.05048137  0.01213488  0.00951967] [0.         0.06764643 0.08456713]\n",
      "[0.06747951 0.02409154 0.00636963] [0.         0.06088178 0.07611042]\n",
      "[-0.05152801  0.00780343  0.00466983] [0.         0.06088178 0.07611042]\n",
      "[0.06034466 0.02102092 0.00385028] [0.         0.05749946 0.07188206]\n",
      "[-0.05205133  0.0056377   0.00224491] [0.         0.05749946 0.07188206]\n",
      "[0.05677724 0.01948561 0.0025906 ] [0.         0.0558083  0.06976788]\n",
      "[-0.05231299  0.00455484  0.00103245] [0.         0.0558083  0.06976788]\n",
      "[0.05499353 0.01871796 0.00196076] [0.         0.05496272 0.06871079]\n",
      "[-0.05244382  0.00401341  0.00042622] [0.         0.05496272 0.06871079]\n",
      "[0.05410167 0.01833413 0.00164584] [0.         0.05453993 0.06818225]\n",
      "[-0.05250923  0.00374269  0.00012311] [0.         0.05453993 0.06818225]\n",
      "[0.05365574 0.01814222 0.00148838] [0.         0.05432854 0.06791797]\n",
      "[-5.25419401e-02  3.60733599e-03 -2.84489228e-05] [0.         0.05432854 0.06791797]\n",
      "[0.05343278 0.01804626 0.00140965] [0.         0.05422284 0.06778584]\n",
      "[-0.05255829  0.00353966 -0.00010423] [0.         0.05422284 0.06778584]\n",
      "[0.0533213  0.01799828 0.00137029] [0.         0.05416999 0.06771977]\n",
      "[-0.05256647  0.00350582 -0.00014212] [0.         0.05416999 0.06771977]\n",
      "[0.05326556 0.01797429 0.00135061] [0.         0.05414356 0.06768674]\n",
      "[-0.05257056  0.0034889  -0.00016106] [0.         0.05414356 0.06768674]\n",
      "[0.05323769 0.0179623  0.00134076] [0.         0.05413035 0.06767022]\n",
      "[-0.0525726   0.00348044 -0.00017053] [0.         0.05413035 0.06767022]\n",
      "[0.05322375 0.0179563  0.00133584] [0.         0.05412375 0.06766196]\n",
      "[-0.05257363  0.00347621 -0.00017527] [0.         0.05412375 0.06766196]\n",
      "[0.05321678 0.0179533  0.00133338] [0.         0.05412044 0.06765783]\n",
      "[-0.05257414  0.00347409 -0.00017764] [0.         0.05412044 0.06765783]\n",
      "[0.0532133  0.0179518  0.00133215] [0.         0.05411879 0.06765577]\n",
      "[-0.05257439  0.00347304 -0.00017882] [0.         0.05411879 0.06765577]\n",
      "[0.05321156 0.01795105 0.00133154] [0.         0.05411797 0.06765473]\n",
      "[-0.05257452  0.00347251 -0.00017941] [0.         0.05411797 0.06765473]\n",
      "[0.05321069 0.01795068 0.00133123] [0.         0.05411755 0.06765422]\n",
      "[-0.05257458  0.00347224 -0.00017971] [0.         0.05411755 0.06765422]\n",
      "[0.05321025 0.01795049 0.00133108] [0.         0.05411735 0.06765396]\n",
      "[-0.05257462  0.00347211 -0.00017986] [0.         0.05411735 0.06765396]\n",
      "[0.05321003 0.0179504  0.001331  ] [0.         0.05411724 0.06765383]\n",
      "[-0.05257463  0.00347204 -0.00017993] [0.         0.05411724 0.06765383]\n",
      "[0.05320992 0.01795035 0.00133096] [0.         0.05411719 0.06765377]\n",
      "[-0.05257464  0.00347201 -0.00017997] [0.         0.05411719 0.06765377]\n",
      "[0.05320987 0.01795033 0.00133094] [0.         0.05411717 0.06765373]\n",
      "[-0.05257464  0.00347199 -0.00017999] [0.         0.05411717 0.06765373]\n",
      "[0.05320984 0.01795032 0.00133093] [0.         0.05411715 0.06765372]\n",
      "[-0.05257465  0.00347199 -0.00018   ] [0.         0.05411715 0.06765372]\n",
      "[0.05320983 0.01795031 0.00133093] [0.         0.05411715 0.06765371]\n",
      "[-0.05257465  0.00347198 -0.00018   ] [0.         0.05411715 0.06765371]\n",
      "[0.05320982 0.01795031 0.00133093] [0.         0.05411714 0.06765371]\n",
      "[-0.05257465  0.00347198 -0.00018   ] [0.         0.05411714 0.06765371]\n",
      "[0.05320982 0.01795031 0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.89793857 0.2087896  0.1140572 ] [0.         0.1754276  0.24388413]\n",
      "[-0.03345422  0.08131333  0.10075403] [0.         0.1754276  0.24388413]\n",
      "[0.47557419 0.11336995 0.05769406] [0.         0.11477237 0.15576892]\n",
      "[-0.04301443  0.04239265  0.05028701] [0.         0.11477237 0.15576892]\n",
      "[0.26439201 0.06566013 0.02951249] [0.         0.08444476 0.11171131]\n",
      "[-0.04779454  0.02293232  0.0250535 ] [0.         0.08444476 0.11171131]\n",
      "[0.15880091 0.04180522 0.01542171] [0.         0.06928095 0.08968251]\n",
      "[-0.05018459  0.01320215  0.01243675] [0.         0.06928095 0.08968251]\n",
      "[0.10600536 0.02987776 0.00837632] [0.         0.06169904 0.0786681 ]\n",
      "[-0.05137962  0.00833706  0.00612837] [0.         0.06169904 0.0786681 ]\n",
      "[0.07960759 0.02391403 0.00485362] [0.         0.05790809 0.0731609 ]\n",
      "[-0.05197713  0.00590452  0.00297418] [0.         0.05790809 0.0731609 ]\n",
      "[0.0664087  0.02093217 0.00309227] [0.         0.05601262 0.0704073 ]\n",
      "[-0.05227589  0.00468825  0.00139709] [0.         0.05601262 0.0704073 ]\n",
      "[0.05980926 0.01944124 0.0022116 ] [0.         0.05506488 0.0690305 ]\n",
      "[-0.05242527  0.00408011  0.00060854] [0.         0.05506488 0.0690305 ]\n",
      "[0.05650954 0.01869577 0.00177126] [0.         0.05459101 0.0683421 ]\n",
      "[-0.05249996  0.00377605  0.00021427] [0.         0.05459101 0.0683421 ]\n",
      "[0.05485968 0.01832304 0.00155109] [0.         0.05435407 0.0679979 ]\n",
      "[-5.25373030e-02  3.62401209e-03  1.71304295e-05] [0.         0.05435407 0.0679979 ]\n",
      "[0.05403475 0.01813667 0.00144101] [0.         0.05423561 0.0678258 ]\n",
      "[-5.25559753e-02  3.54799515e-03 -8.14379640e-05] [0.         0.05423561 0.0678258 ]\n",
      "[0.05362228 0.01804349 0.00138597] [0.         0.05417637 0.06773975]\n",
      "[-0.05256531  0.00350999 -0.00013072] [0.         0.05417637 0.06773975]\n",
      "[0.05341605 0.0179969  0.00135844] [0.         0.05414676 0.06769673]\n",
      "[-0.05256998  0.00349098 -0.00015536] [0.         0.05414676 0.06769673]\n",
      "[0.05331293 0.0179736  0.00134468] [0.         0.05413195 0.06767521]\n",
      "[-0.05257231  0.00348148 -0.00016769] [0.         0.05413195 0.06767521]\n",
      "[0.05326137 0.01796195 0.0013378 ] [0.         0.05412454 0.06766446]\n",
      "[-0.05257348  0.00347673 -0.00017385] [0.         0.05412454 0.06766446]\n",
      "[0.05323559 0.01795613 0.00133436] [0.         0.05412084 0.06765908]\n",
      "[-0.05257406  0.00347435 -0.00017693] [0.         0.05412084 0.06765908]\n",
      "[0.0532227  0.01795322 0.00133264] [0.         0.05411899 0.06765639]\n",
      "[-0.05257436  0.00347317 -0.00017847] [0.         0.05411899 0.06765639]\n",
      "[0.05321626 0.01795176 0.00133178] [0.         0.05411807 0.06765505]\n",
      "[-0.0525745   0.00347257 -0.00017924] [0.         0.05411807 0.06765505]\n",
      "[0.05321304 0.01795103 0.00133135] [0.         0.0541176  0.06765437]\n",
      "[-0.05257457  0.00347228 -0.00017962] [0.         0.0541176  0.06765437]\n",
      "[0.05321143 0.01795067 0.00133114] [0.         0.05411737 0.06765404]\n",
      "[-0.05257461  0.00347213 -0.00017981] [0.         0.05411737 0.06765404]\n",
      "[0.05321062 0.01795049 0.00133103] [0.         0.05411726 0.06765387]\n",
      "[-0.05257463  0.00347205 -0.00017991] [0.         0.05411726 0.06765387]\n",
      "[0.05321022 0.0179504  0.00133098] [0.         0.0541172  0.06765379]\n",
      "[-0.05257464  0.00347202 -0.00017996] [0.         0.0541172  0.06765379]\n",
      "[0.05321002 0.01795035 0.00133095] [0.         0.05411717 0.06765374]\n",
      "[-0.05257464  0.003472   -0.00017998] [0.         0.05411717 0.06765374]\n",
      "[0.05320992 0.01795033 0.00133094] [0.         0.05411715 0.06765372]\n",
      "[-0.05257465  0.00347199 -0.00017999] [0.         0.05411715 0.06765372]\n",
      "[0.05320987 0.01795032 0.00133093] [0.         0.05411715 0.06765371]\n",
      "[-0.05257465  0.00347198 -0.00018   ] [0.         0.05411715 0.06765371]\n",
      "[0.05320984 0.01795031 0.00133093] [0.         0.05411714 0.06765371]\n",
      "[-0.05257465  0.00347198 -0.00018   ] [0.         0.05411714 0.06765371]\n",
      "[0.05320983 0.01795031 0.00133092] [0.         0.05411714 0.06765371]\n",
      "[-0.05257465  0.00347198 -0.00018   ] [0.         0.05411714 0.06765371]\n",
      "[0.05320982 0.01795031 0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.01795031 0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[0.05320982 0.0179503  0.00133092] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465  0.00347198 -0.00018001] [0.         0.05411714 0.0676537 ]\n",
      "[-0.05257465 -0.00193974 -0.00694538] [0.         0.05411714 0.0676537 ]\n",
      "[-0.12945364 -0.01367764  0.15024958] [0.         0.05411714 0.0676537 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Part Name |     Score | Feedback\n",
      "                                  --------- |     ----- | --------\n",
      "Regularized Linear Regression Cost Function |  25 /  25 | Nice work!\n",
      "     Regularized Linear Regression Gradient |  25 /  25 | Nice work!\n",
      "                             Learning Curve |   0 /  20 | \n",
      "                 Polynomial Feature Mapping |   0 /  10 | \n",
      "                           Validation Curve |   0 /  20 | \n",
      "                                  --------------------------------\n",
      "                                            |  50 / 100 |  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "grader[3] = learningCurve\n",
    "grader.grade()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>\n",
    "\n",
    "## 3 Polynomial regression\n",
    "\n",
    "The problem with our linear model was that it was too simple for the data\n",
    "and resulted in underfitting (high bias). In this part of the exercise, you will address this problem by adding more features. For polynomial regression, our hypothesis has the form:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "h_\\theta(x)  &= \\theta_0 + \\theta_1 \\times (\\text{waterLevel}) + \\theta_2 \\times (\\text{waterLevel})^2 + \\cdots + \\theta_p \\times (\\text{waterLevel})^p \\\\\n",
    "& = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\cdots + \\theta_p x_p\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Notice that by defining $x_1 = (\\text{waterLevel})$, $x_2 = (\\text{waterLevel})^2$ , $\\cdots$, $x_p =\n",
    "(\\text{waterLevel})^p$, we obtain a linear regression model where the features are the various powers of the original value (waterLevel).\n",
    "\n",
    "Now, you will add more features using the higher powers of the existing feature $x$ in the dataset. Your task in this part is to complete the code in the function `polyFeatures` in the next cell. The function should map the original training set $X$ of size $m \\times 1$ into its higher powers. Specifically, when a training set $X$ of size $m \\times 1$ is passed into the function, the function should return a $m \\times p$ matrix `X_poly`, where column 1 holds the original values of X, column 2 holds the values of $X^2$, column 3 holds the values of $X^3$, and so on. Note that you don’t have to account for the zero-eth power in this function.\n",
    "\n",
    "<a id=\"polyFeatures\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyFeatures(X, p):\n",
    "    \"\"\"\n",
    "    Maps X (1D vector) into the p-th power.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        A data vector of size m, where m is the number of examples.\n",
    "    \n",
    "    p : int\n",
    "        The polynomial power to map the features. \n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    X_poly : array_like\n",
    "        A matrix of shape (m x p) where p is the polynomial \n",
    "        power and m is the number of examples. That is:\n",
    "    \n",
    "        X_poly[i, :] = [X[i], X[i]**2, X[i]**3 ...  X[i]**p]\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Given a vector X, return a matrix X_poly where the p-th column of\n",
    "    X contains the values of X to the p-th power.\n",
    "    \"\"\"\n",
    "    # You need to return the following variables correctly.\n",
    "    X_poly = np.zeros((X.shape[0], p))\n",
    "\n",
    "    # ===========abs=========== YOUR CODE HERE ======================\n",
    "        \n",
    "    for i in range(p):\n",
    "        X_poly[:, i] = X[:, 0] ** (i + 1)\n",
    "    # ============================================================\n",
    "    return X_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have a function that will map features to a higher dimension. The next cell will apply it to the training set, the test set, and the cross validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Training Example 1:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.        , -0.36214078, -0.75508669,  0.18222588, -0.70618991,\n",
       "        0.30661792, -0.59087767,  0.3445158 , -0.50848117])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 8\n",
    "\n",
    "# Map X onto Polynomial Features and Normalize\n",
    "X_poly = polyFeatures(X, p)\n",
    "X_poly, mu, sigma = utils.featureNormalize(X_poly)\n",
    "X_poly = np.concatenate([np.ones((m, 1)), X_poly], axis=1)\n",
    "\n",
    "# Map X_poly_test and normalize (using mu and sigma)\n",
    "X_poly_test = polyFeatures(Xtest, p)\n",
    "X_poly_test -= mu\n",
    "X_poly_test /= sigma\n",
    "X_poly_test = np.concatenate([np.ones((ytest.size, 1)), X_poly_test], axis=1)\n",
    "\n",
    "# Map X_poly_val and normalize (using mu and sigma)\n",
    "X_poly_val = polyFeatures(Xval, p)\n",
    "X_poly_val -= mu\n",
    "X_poly_val /= sigma\n",
    "X_poly_val = np.concatenate([np.ones((yval.size, 1)), X_poly_val], axis=1)\n",
    "\n",
    "print('Normalized Training Example 1:')\n",
    "X_poly[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You should now submit your solutions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitting Solutions | Programming Exercise regularized-linear-regression-and-bias-variance\n",
      "\n",
      "Use token from last successful submission (nirmalhk7@gmail.com)? (Y/n): y\n",
      "                                  Part Name |     Score | Feedback\n",
      "                                  --------- |     ----- | --------\n",
      "Regularized Linear Regression Cost Function |  25 /  25 | Nice work!\n",
      "     Regularized Linear Regression Gradient |  25 /  25 | Nice work!\n",
      "                             Learning Curve |   0 /  20 | \n",
      "                 Polynomial Feature Mapping |  10 /  10 | Nice work!\n",
      "                           Validation Curve |   0 /  20 | \n",
      "                                  --------------------------------\n",
      "                                            |  60 / 100 |  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "grader[4] = polyFeatures\n",
    "grader.grade()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Learning Polynomial Regression\n",
    "\n",
    "After you have completed the function `polyFeatures`, we will proceed to train polynomial regression using your linear regression cost function.\n",
    "\n",
    "Keep in mind that even though we have polynomial terms in our feature vector, we are still solving a linear regression optimization problem. The polynomial terms have simply turned into features that we can use for linear regression. We are using the same cost function and gradient that you wrote for the earlier part of this exercise.\n",
    "\n",
    "For this part of the exercise, you will be using a polynomial of degree 8. It turns out that if we run the training directly on the projected data, will not work well as the features would be badly scaled (e.g., an example with $x = 40$ will now have a feature $x_8 = 40^8 = 6.5 \\times 10^{12}$). Therefore, you will\n",
    "need to use feature normalization.\n",
    "\n",
    "Before learning the parameters $\\theta$ for the polynomial regression, we first call `featureNormalize` and normalize the features of the training set, storing the mu, sigma parameters separately. We have already implemented this function for you (in `utils.py` module) and it is the same function from the first exercise.\n",
    "\n",
    "After learning the parameters $\\theta$, you should see two plots generated for polynomial regression with $\\lambda = 0$, which should be similar to the ones here:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"Figures/polynomial_regression.png\"></td>\n",
    "        <td><img src=\"Figures/polynomial_learning_curve.png\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "You should see that the polynomial fit is able to follow the datapoints very well, thus, obtaining a low training error. The figure on the right shows that the training error essentially stays zero for all numbers of training samples. However, the polynomial fit is very complex and even drops off at the extremes. This is an indicator that the polynomial regression model is overfitting the training data and will not generalize well.\n",
    "\n",
    "To better understand the problems with the unregularized ($\\lambda = 0$) model, you can see that the learning curve  shows the same effect where the training error is low, but the cross validation error is high. There is a gap between the training and cross validation errors, indicating a high variance problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression (lambda = 0.000000)\n",
      "\n",
      "# Training Examples\tTrain Error\tCross Validation Error\n",
      "  \t1\t\t0.244264\t169.612359\n",
      "  \t2\t\t0.208918\t169.468604\n",
      "  \t3\t\t35.805954\t197.153658\n",
      "  \t4\t\t43.434748\t223.567983\n",
      "  \t5\t\t165.133209\t116.356611\n",
      "  \t6\t\t231.813122\t174.284241\n",
      "  \t7\t\t211.088902\t176.077730\n",
      "  \t8\t\t171.674536\t159.762988\n",
      "  \t9\t\t71.880207\t78.627711\n",
      "  \t10\t\t139.877689\t163.571897\n",
      "  \t11\t\t93.434224\t108.571366\n",
      "  \t12\t\t140.847165\t165.468651\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lambda_ = 0\n",
    "theta = utils.trainLinearReg(linearRegCostFunction, X_poly, y,\n",
    "                             lambda_=lambda_, maxiter=55)\n",
    "\n",
    "# Plot training data and fit\n",
    "pyplot.plot(X, y, 'ro', ms=10, mew=1.5, mec='k')\n",
    "\n",
    "utils.plotFit(polyFeatures, np.min(X), np.max(X), mu, sigma, theta, p)\n",
    "\n",
    "pyplot.xlabel('Change in water level (x)')\n",
    "pyplot.ylabel('Water flowing out of the dam (y)')\n",
    "pyplot.title('Polynomial Regression Fit (lambda = %f)' % lambda_)\n",
    "pyplot.ylim([-20, 50])\n",
    "\n",
    "pyplot.figure()\n",
    "error_train, error_val = learningCurve(X_poly, y, X_poly_val, yval, lambda_)\n",
    "pyplot.plot(np.arange(1, 1+m), error_train, np.arange(1, 1+m), error_val)\n",
    "\n",
    "pyplot.title('Polynomial Regression Learning Curve (lambda = %f)' % lambda_)\n",
    "pyplot.xlabel('Number of training examples')\n",
    "pyplot.ylabel('Error')\n",
    "pyplot.axis([0, 13, 0, 100])\n",
    "pyplot.legend(['Train', 'Cross Validation'])\n",
    "\n",
    "print('Polynomial Regression (lambda = %f)\\n' % lambda_)\n",
    "print('# Training Examples\\tTrain Error\\tCross Validation Error')\n",
    "for i in range(m):\n",
    "    print('  \\t%d\\t\\t%f\\t%f' % (i+1, error_train[i], error_val[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to combat the overfitting (high-variance) problem is to add regularization to the model. In the next section, you will get to  try different $\\lambda$ parameters to see how regularization can lead to a better model.\n",
    "\n",
    "### 3.2 Optional (ungraded) exercise: Adjusting the regularization parameter\n",
    "\n",
    "In this section, you will get to observe how the regularization parameter affects the bias-variance of regularized polynomial regression. You should now modify the the lambda parameter and try $\\lambda = 1, 100$. For each of these values, the script should generate a polynomial fit to the data and also a learning curve.\n",
    "\n",
    "For $\\lambda = 1$, the generated plots should look like the the figure below. You should see a polynomial fit that follows the data trend well (left) and a learning curve (right) showing that both the cross validation and training error converge to a relatively low value. This shows the $\\lambda = 1$ regularized polynomial regression model does not have the high-bias or high-variance problems. In effect, it achieves a good trade-off between bias and variance.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"Figures/polynomial_regression_reg_1.png\"></td>\n",
    "        <td><img src=\"Figures/polynomial_learning_curve_reg_1.png\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "For $\\lambda = 100$, you should see a polynomial fit (figure below) that does not follow the data well. In this case, there is too much regularization and the model is unable to fit the training data.\n",
    "\n",
    "![](Figures/polynomial_regression_reg_100.png)\n",
    "\n",
    "*You do not need to submit any solutions for this optional (ungraded) exercise.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "### 3.3 Selecting $\\lambda$ using a cross validation set\n",
    "\n",
    "From the previous parts of the exercise, you observed that the value of $\\lambda$ can significantly affect the results of regularized polynomial regression on the training and cross validation set. In particular, a model without regularization ($\\lambda = 0$) fits the training set well, but does not generalize. Conversely, a model with too much regularization ($\\lambda = 100$) does not fit the training set and testing set well. A good choice of $\\lambda$ (e.g., $\\lambda = 1$) can provide a good fit to the data.\n",
    "\n",
    "In this section, you will implement an automated method to select the $\\lambda$ parameter. Concretely, you will use a cross validation set to evaluate how good each $\\lambda$ value is. After selecting the best $\\lambda$ value using the cross validation set, we can then evaluate the model on the test set to estimate\n",
    "how well the model will perform on actual unseen data. \n",
    "\n",
    "Your task is to complete the code in the function `validationCurve`. Specifically, you should should use the `utils.trainLinearReg` function to train the model using different values of $\\lambda$ and compute the training error and cross validation error. You should try $\\lambda$ in the following range: {0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10}.\n",
    "<a id=\"validationCurve\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validationCurve(X, y, Xval, yval):\n",
    "    \"\"\"\n",
    "    Generate the train and validation errors needed to plot a validation\n",
    "    curve that we can use to select lambda_.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The training dataset. Matrix with shape (m x n) where m is the \n",
    "        total number of training examples, and n is the number of features \n",
    "        including any polynomial features.\n",
    "    \n",
    "    y : array_like\n",
    "        The functions values at each training datapoint. A vector of\n",
    "        shape (m, ).\n",
    "    \n",
    "    Xval : array_like\n",
    "        The validation dataset. Matrix with shape (m_val x n) where m is the \n",
    "        total number of validation examples, and n is the number of features \n",
    "        including any polynomial features.\n",
    "    \n",
    "    yval : array_like\n",
    "        The functions values at each validation datapoint. A vector of\n",
    "        shape (m_val, ).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    lambda_vec : list\n",
    "        The values of the regularization parameters which were used in \n",
    "        cross validation.\n",
    "    \n",
    "    error_train : list\n",
    "        The training error computed at each value for the regularization\n",
    "        parameter.\n",
    "    \n",
    "    error_val : list\n",
    "        The validation error computed at each value for the regularization\n",
    "        parameter.\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Fill in this function to return training errors in `error_train` and\n",
    "    the validation errors in `error_val`. The vector `lambda_vec` contains\n",
    "    the different lambda parameters to use for each calculation of the\n",
    "    errors, i.e, `error_train[i]`, and `error_val[i]` should give you the\n",
    "    errors obtained after training with `lambda_ = lambda_vec[i]`.\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    You can loop over lambda_vec with the following:\n",
    "    \n",
    "          for i in range(len(lambda_vec))\n",
    "              lambda = lambda_vec[i]\n",
    "              # Compute train / val errors when training linear \n",
    "              # regression with regularization parameter lambda_\n",
    "              # You should store the result in error_train[i]\n",
    "              # and error_val[i]\n",
    "              ....\n",
    "    \"\"\"\n",
    "    # Selected values of lambda (you should not change this)\n",
    "    lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]\n",
    "\n",
    "    # You need to return these variables correctly.\n",
    "    error_train = np.zeros(len(lambda_vec))\n",
    "    error_val = np.zeros(len(lambda_vec))\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    for i in range(len(lambda_vec)):\n",
    "        lambda_try = lambda_vec[i]\n",
    "        theta_t = utils.trainLinearReg(linearRegCostFunction, X, y, lambda_ = lambda_try)\n",
    "        error_train[i], _ = linearRegCostFunction(X, y, theta_t, lambda_ = 0)\n",
    "        error_val[i], _ = linearRegCostFunction(Xval, yval, theta_t, lambda_ = 0)\n",
    "\n",
    "    # ============================================================\n",
    "    return lambda_vec, error_train, error_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have completed the code, the next cell will run your function and plot a cross validation curve of error v.s. $\\lambda$ that allows you select which $\\lambda$ parameter to use. You should see a plot similar to the figure below. \n",
    "\n",
    "![](Figures/cross_validation.png)\n",
    "\n",
    "In this figure, we can see that the best value of $\\lambda$ is around 3. Due to randomness\n",
    "in the training and validation splits of the dataset, the cross validation error can sometimes be lower than the training error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda\t\tTrain Error\tValidation Error\n",
      " 0.000000\t140.847165\t165.468651\n",
      " 0.001000\t140.847216\t165.467857\n",
      " 0.003000\t140.847353\t165.466201\n",
      " 0.010000\t140.847819\t165.460546\n",
      " 0.030000\t140.849057\t165.444237\n",
      " 0.100000\t140.853445\t165.387901\n",
      " 0.300000\t140.865812\t165.233420\n",
      " 1.000000\t140.901730\t164.803618\n",
      " 3.000000\t140.940960\t164.324013\n",
      " 10.000000\t140.953303\t164.141092\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lambda_vec, error_train, error_val = validationCurve(X_poly, y, X_poly_val, yval)\n",
    "\n",
    "pyplot.plot(lambda_vec, error_train, '-o', lambda_vec, error_val, '-o', lw=2)\n",
    "pyplot.legend(['Train', 'Cross Validation'])\n",
    "pyplot.xlabel('lambda')\n",
    "pyplot.ylabel('Error')\n",
    "\n",
    "print('lambda\\t\\tTrain Error\\tValidation Error')\n",
    "for i in range(len(lambda_vec)):\n",
    "    print(' %f\\t%f\\t%f' % (lambda_vec[i], error_train[i], error_val[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You should now submit your solutions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitting Solutions | Programming Exercise regularized-linear-regression-and-bias-variance\n",
      "\n",
      "Use token from last successful submission (nirmalhk7@gmail.com)? (Y/n): y\n",
      "                                  Part Name |     Score | Feedback\n",
      "                                  --------- |     ----- | --------\n",
      "Regularized Linear Regression Cost Function |  25 /  25 | Nice work!\n",
      "     Regularized Linear Regression Gradient |  25 /  25 | Nice work!\n",
      "                             Learning Curve |   0 /  20 | \n",
      "                 Polynomial Feature Mapping |  10 /  10 | Nice work!\n",
      "                           Validation Curve |   0 /  20 | \n",
      "                                  --------------------------------\n",
      "                                            |  60 / 100 |  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "grader[5] = validationCurve\n",
    "grader.grade()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4  Optional (ungraded) exercise: Computing test set error\n",
    "\n",
    "In the previous part of the exercise, you implemented code to compute the cross validation error for various values of the regularization parameter $\\lambda$. However, to get a better indication of the model’s performance in the real world, it is important to evaluate the “final” model on a test set that was not used in any part of training (that is, it was neither used to select the $\\lambda$ parameters, nor to learn the model parameters $\\theta$). For this optional (ungraded) exercise, you should compute the test error using the best value of $\\lambda$ you found. In our cross validation, we obtained a test error of 3.8599 for $\\lambda = 3$.\n",
    "\n",
    "*You do not need to submit any solutions for this optional (ungraded) exercise.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Optional (ungraded) exercise: Plotting learning curves with randomly selected examples\n",
    "\n",
    "In practice, especially for small training sets, when you plot learning curves to debug your algorithms, it is often helpful to average across multiple sets of randomly selected examples to determine the training error and cross validation error.\n",
    "\n",
    "Concretely, to determine the training error and cross validation error for $i$ examples, you should first randomly select $i$ examples from the training set and $i$ examples from the cross validation set. You will then learn the parameters $\\theta$ using the randomly chosen training set and evaluate the parameters $\\theta$ on the randomly chosen training set and cross validation set. The above steps should then be repeated multiple times (say 50) and the averaged error should be used to determine the training error and cross validation error for $i$ examples.\n",
    "\n",
    "For this optional (ungraded) exercise, you should implement the above strategy for computing the learning curves. For reference, the figure below  shows the learning curve we obtained for polynomial regression with $\\lambda = 0.01$. Your figure may differ slightly due to the random selection of examples.\n",
    "\n",
    "![](Figures/learning_curve_random.png)\n",
    "\n",
    "*You do not need to submit any solutions for this optional (ungraded) exercise.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
